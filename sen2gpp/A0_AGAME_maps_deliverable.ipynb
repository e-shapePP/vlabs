{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGAME Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPP maps (15 sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis code includes all the steps needed to compute GPP maps with AGAME methodology:\\nThe methodology includes the following steps:\\n\\n1)Get icos tables (15 sites)\\n2)Get Sentinel-2 tables (15 sites)\\n3)Get ecosystem boundaries (15 sites)\\n4)Combine tables\\n5)Train XGBoost model\\n6)Evaluate XGBoost model\\n7)Create GPP maps (15 sites) <-----------------------------------------\\n8)Creata uncertainty maps\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This code includes all the steps needed to compute GPP maps with AGAME methodology:\n",
    "The methodology includes the following steps:\n",
    "\n",
    "1)Get icos tables (15 sites)\n",
    "2)Get Sentinel-2 tables (15 sites)\n",
    "3)Get ecosystem boundaries (15 sites)\n",
    "4)Combine tables\n",
    "5)Train XGBoost model\n",
    "6)Evaluate XGBoost model\n",
    "7)Create GPP maps (15 sites) <-----------------------------------------\n",
    "8)Creata uncertainty maps\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deims\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import ee\n",
    "import xarray\n",
    "import geemap\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "from xgboost import XGBRegressor\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import Polygon\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_unique_years(date_range_values):\n",
    "    unique_years = set()\n",
    "    for date in date_range_values:\n",
    "        year = date.split('-')[0] \n",
    "        unique_years.add(year)    \n",
    "\n",
    "    unique_years = sorted(unique_years)\n",
    "\n",
    "    return unique_years\n",
    "\n",
    "def get_coordinates_area(df, site):\n",
    "    site_url = df['deims'].loc[df['site name'] == site].values[0]\n",
    "    latitude  = df['latitude'].loc[df['site name'] == site].values[0]\n",
    "    longitude = df['longitude'].loc[df['site name'] == site].values[0]\n",
    "    if pd.isna(site_url):\n",
    "        raise ValueError(\"The site DEIMS url is empty. Please provide a valid site URL.\")\n",
    "    else:\n",
    "        boundaries   = deims.getSiteBoundaries([site_url])\n",
    "        information = deims.getSiteById(site_id=site_url)\n",
    "    return boundaries, latitude, longitude, information\n",
    "\n",
    "def map_coordinates_area(df, boundaries, site):\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "        crs=\"EPSG:3857\"\n",
    "    )\n",
    "    gdf = gdf.loc[gdf['site name'] == site]\n",
    "    centroid = gdf.geometry.centroid.union_all()\n",
    "    m = folium.Map(location=[centroid.y, centroid.x], zoom_start=12)\n",
    "    for idx, row in gdf.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=row['site name']\n",
    "        ).add_to(m)\n",
    "\n",
    "    folium.GeoJson(boundaries).add_to(m)\n",
    "\n",
    "    return m\n",
    "\n",
    "def get_gee_area(boundaries):\n",
    "    total_bounds = boundaries.total_bounds\n",
    "    aoi = ee.Geometry.Rectangle([total_bounds[0], total_bounds[1], total_bounds[2], total_bounds[3]])\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 10)\n",
    "\n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp(polygon_gdf):\n",
    "    # Ensure the GeoDataFrame contains a valid geometry column\n",
    "    if polygon_gdf.empty or polygon_gdf.geom_type.iloc[0] != 'Polygon':\n",
    "        raise ValueError(\"GeoDataFrame is empty or does not contain Polygon geometries.\")\n",
    "    \n",
    "    # Get the first polygon from the GeoDataFrame\n",
    "    polygon = polygon_gdf.geometry.iloc[0]\n",
    "\n",
    "    # Convert the Shapely Polygon to GeoJSON-like dict\n",
    "    geojson = mapping(polygon)\n",
    "    \n",
    "    # Create an Earth Engine Geometry from the GeoJSON\n",
    "    aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp_multipolygon(geodf):\n",
    "    \n",
    "    if geodf.empty:\n",
    "        raise ValueError(\"GeoDataFrame is empty.\")\n",
    "    \n",
    "    # Get the first geometry from the GeoDataFrame\n",
    "    geom = geodf.geometry.iloc[0]\n",
    "\n",
    "    # Check the geometry type\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geojson = mapping(geom)\n",
    "        aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        # Convert each Polygon in the MultiPolygon to GeoJSON and create ee.Geometry.MultiPolygon\n",
    "        geojson = mapping(geom)\n",
    "        polygons = [ee.Geometry.Polygon(polygon) for polygon in geojson['coordinates']]\n",
    "        aoi = ee.Geometry.MultiPolygon(polygons)\n",
    "        # aoi = ee.Geometry.Polygon(polygons[0])\n",
    "    else:\n",
    "        raise ValueError(\"GeoDataFrame contains unsupported geometry type. Only Polygon and MultiPolygon are supported.\")\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp_multipolygon_single_polygon(geodf, num_polygon):\n",
    "    \n",
    "    if geodf.empty:\n",
    "        raise ValueError(\"GeoDataFrame is empty.\")\n",
    "    \n",
    "    # Get the first geometry from the GeoDataFrame\n",
    "    geom = geodf.geometry.iloc[0]\n",
    "\n",
    "    # Check the geometry type\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geojson = mapping(geom)\n",
    "        aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        # Convert each Polygon in the MultiPolygon to GeoJSON and create ee.Geometry.MultiPolygon\n",
    "        geojson = mapping(geom)\n",
    "        first_polygon_coords = geojson['coordinates'][num_polygon]\n",
    "        polygon = Polygon(first_polygon_coords[0]) \n",
    "        geojson_polygon = polygon.__geo_interface__\n",
    "        aoi = ee.Geometry.Polygon(geojson_polygon['coordinates'])\n",
    "    else:\n",
    "        raise ValueError(\"GeoDataFrame contains unsupported geometry type. Only Polygon and MultiPolygon are supported.\")\n",
    "    \n",
    "    area_m2 = aoi.area().getInfo()\n",
    "    area_km2 = area_m2 / 1e6\n",
    "    print(f\"The area of the site is {area_m2} square meters\")\n",
    "    print(f\"The area of the site is {area_km2} square kilometers\")\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, \"Site's area\")\n",
    "\n",
    "    if area_km2 < 1:\n",
    "        print(f\"The area of the site is below 1 square kilometer. A new area with a minimun of 1 square kilometer will be created\")\n",
    "        centroid = aoi.centroid()\n",
    "        buffer = centroid.buffer(500)\n",
    "        aoi = buffer.bounds()\n",
    "        error_margin = 1  # meter\n",
    "        area_m2 = aoi.area(maxError=error_margin).getInfo()\n",
    "        area_km2 = area_m2 / 1e6\n",
    "        print(f\"The new area of the site is {area_m2} square meters\")\n",
    "        print(f\"The mew area of the site is {area_km2} square kilometers\")\n",
    "        Map.addLayer(aoi, {}, \"New site's area\")\n",
    "        \n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "\n",
    "    print(f\"The site geometry is ready to extract Earth Observation data\\n\")\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def apply_scale_factors_s2(image):\n",
    "    optical_bands = image.select(['B.']).divide(10000)\n",
    "    thermal_bands = image.select(['B.*']).divide(10000)\n",
    "    return image.addBands(optical_bands, None, True).addBands(thermal_bands, None, True)\n",
    "\n",
    "def apply_scale_factors_e5(image):\n",
    "    image = image.divide(24*60*60)\n",
    "    return image\n",
    "\n",
    "# function to derive VIs\n",
    "def calculateVI(image):\n",
    "    '''This method calculates different vegetation indices in a image collection and adds their values as new bands'''\n",
    "\n",
    "    # defining dictionary of bands Sentinel-2 \n",
    "    dict_bands = {\n",
    "\n",
    "        \"blue\"  :  'B2',                              #Blue band                        \n",
    "        \"green\" :  'B3',                              #Green band\n",
    "        \"red\"   :  'B4',                              #Red band\n",
    "        \"red1\"  :  'B5',                              #Red-edge spectral band   \n",
    "        \"red2\"  :  'B6',                              #Red-edge spectral band\n",
    "        \"red3\"  :  'B7',                              #Red-edge spectral band    \n",
    "        \"NIR\"   :  'B8',                              #Near-infrared band\n",
    "        \"NIRn\"  :  'B8A',                             #Near-infrared narrow\n",
    "        \"WV\"    :  'B9',                              #Water vapour\n",
    "        \"SWIR1\" :  'B11',                             #Short wave infrared 1\n",
    "        \"SWIR2\" :  'B12',                             #Short wave infrared 2\n",
    "    }\n",
    "\n",
    "    # specify bands \n",
    "    dict  = dict_bands\n",
    "    blue  = dict[\"blue\"]                              #Blue band                        \n",
    "    green = dict[\"green\"]                             #Green band\n",
    "    red   = dict[\"red\"]                               #Red band\n",
    "    red1  = dict[\"red1\"]                              #Red-edge spectral band    \n",
    "    red2  = dict[\"red2\"]                              #Red-edge spectral band\n",
    "    red3  = dict[\"red3\"]                              #Red-edge spectral band\n",
    "    NIR   = dict[\"NIR\"]                               #Near-infrared band\n",
    "    NIRn  = dict[\"NIRn\"]                              #Near-infrared band\n",
    "    WV    = dict[\"WV\"]                                #Water vapour\n",
    "    SWIR1 = dict[\"SWIR1\"]                             #Short wave infrared 1\n",
    "    SWIR2 = dict[\"SWIR2\"]                             #Short wave infrared 2\n",
    "\n",
    "    bands_for_expressions = {\n",
    "\n",
    "        'blue'  : image.select(blue).divide(10000),\n",
    "        'green' : image.select(green).divide(10000), \n",
    "        'red'   : image.select(red).divide(10000),\n",
    "        'red1'  : image.select(red1).divide(10000), \n",
    "        'red2'  : image.select(red2).divide(10000),\n",
    "        'red3'  : image.select(red3).divide(10000), \n",
    "        'NIR'   : image.select(NIR).divide(10000),\n",
    "        'NIRn'  : image.select(NIRn).divide(10000),\n",
    "        'WV'    : image.select(WV).divide(10000),\n",
    "        'SWIR1' : image.select(SWIR1).divide(10000),\n",
    "        'SWIR2' : image.select(SWIR2).divide(10000)}\n",
    "\n",
    "    # greeness related indices\n",
    "    # NDVI                                                                             (Rouse et al., 1974)\n",
    "    NDVI  = image.normalizedDifference([NIR, red]).rename(\"NDVI\") \n",
    "    # EVI                                                                             \n",
    "    EVI   = image.expression('2.5*(( NIR - red ) / ( NIR + 6 * red - 7.5 * blue + 1 ))', \n",
    "            bands_for_expressions).rename(\"EVI\")\n",
    "    # EVI2                                                                             (Jiang et al., 2008)\n",
    "    EVI2  = image.expression('2.5*(( NIR - red ) / ( NIR + 2.4 * red + 1 ))', \n",
    "            bands_for_expressions).rename(\"EVI2\")\n",
    "\n",
    "    # greeness related indices with Sentinel-2 narrow bands / Red-edge\n",
    "    # Clr\n",
    "    CLr  = image.expression('(red3/red1)-1', bands_for_expressions).rename(\"CLr\")\n",
    "    # Clg\n",
    "    Clg  = image.expression('(red3/green)-1', bands_for_expressions).rename(\"CLg\")\n",
    "    # MTCI\n",
    "    MTCI = image.expression('(red2-red1)/(red1-red)', bands_for_expressions).rename(\"MTCI\")\n",
    "    # MNDVI                                                                            (Add reference)\n",
    "    MNDVI = image.normalizedDifference([red3, red1]).rename(\"MNDVI\")    \n",
    "\n",
    "    # water related indices\n",
    "    # MNDWI                                                                            (Add reference)\n",
    "    MNDWI = image.normalizedDifference([green, SWIR1]).rename(\"MNDWI\")    \n",
    "    # NDWI OR LSWI or NDII or NDMI                                                     (Add reference)\n",
    "    LSWI  = image.normalizedDifference([NIR, SWIR1]).rename(\"LSWI\")\n",
    "    # NDII                                                                             (Hunt & Qu, 2013)\n",
    "    NDII   = image.normalizedDifference([NIR, SWIR2]).rename(\"NDII\")\n",
    "\n",
    "    image = image.addBands(NDVI).addBands(EVI).addBands(EVI2)\n",
    "    image = image.addBands(CLr).addBands(Clg).addBands(MTCI).addBands(MNDVI)\n",
    "    image = image.addBands(MNDWI).addBands(LSWI).addBands(NDII)\n",
    "\n",
    "    return image \n",
    "\n",
    "def get_s2_array(period,aoi,sentinel_bands,MGRS_TILE=None,cloud_percentage=100,resolution=100):\n",
    "    ic = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterDate(period[0],period[1])\n",
    "    # ic = ic.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',cloud_percentage))\n",
    "    ic = ic.filterBounds(aoi) \n",
    "    if not MGRS_TILE   is None:\n",
    "        print(f'Retriving collection for {MGRS_TILE} tile')\n",
    "        ic = ic.filter(ee.Filter.eq('MGRS_TILE', MGRS_TILE)) \n",
    "    ic = ic.map(apply_scale_factors_s2)\n",
    "    ic = ic.map(calculateVI)\n",
    "    ic = ic.select(sentinel_bands)\n",
    "\n",
    "    count = ic.size().getInfo()\n",
    "    print('Number of images:', count)\n",
    "    image_names = ic.aggregate_array('system:id').getInfo()\n",
    "    print('Image names:', image_names)\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No images found in the period.\")\n",
    "\n",
    "    if count > 1:\n",
    "        print(\"More than one image in the period.\")\n",
    "\n",
    "\n",
    "        print('Selecting the first image in the collection:', image_names[0])\n",
    "        \n",
    "        ic = ic.filter(ee.Filter.eq('system:id', image_names[0]))\n",
    "        count = ic.size().getInfo()\n",
    "        print('Number of images:', count)\n",
    "        image_names = ic.aggregate_array('system:id').getInfo()\n",
    "        print('Image names:', image_names)\n",
    "\n",
    "    # ic = ee.ImageCollection(ic.mean())\n",
    "    ic_sample = ic.getRegion(aoi, resolution).getInfo()\n",
    "    return ic_sample, ic\n",
    "\n",
    "def get_s2_df(s2_array):\n",
    "    df = pd.DataFrame(s2_array[1:], columns=s2_array[0])\n",
    "    df = df.iloc[:,1:]\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms').dt.date\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_e5_array(period,aoi,e5_bands,resolution=100):\n",
    "    e5 = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR').filterDate(period[0],period[1])\n",
    "    e5 = e5.filterBounds(aoi).select(e5_bands)\n",
    "    e5 = e5.map(apply_scale_factors_e5)\n",
    "    e5_sample = e5.getRegion(aoi, resolution).getInfo()\n",
    "    return e5_sample, e5\n",
    "\n",
    "def get_e5_df(e5_array):\n",
    "    dfe5 = pd.DataFrame(e5_array[1:], columns=e5_array[0])\n",
    "    dfe5['time'] = pd.to_datetime(dfe5['id'], format='%Y%m%d')\n",
    "    dfe5 = dfe5.iloc[:,1:]\n",
    "    dfe5.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    dfe5.rename(columns={'surface_net_solar_radiation_sum':'SW_IN_ERA_GEE'}, inplace=True)\n",
    "    return dfe5\n",
    "\n",
    "def merge_s2_e5(s2_df, e5_df):\n",
    "    df1 = s2_df.reset_index()\n",
    "    df2 = e5_df.reset_index()\n",
    "    df_merged = df1.merge(df2, on=['time', 'latitude', 'longitude'], how='left')\n",
    "\n",
    "    df_merged = df_merged.dropna()\n",
    "    df_merged.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df_merged\n",
    "\n",
    "def map_image(ic, aoi, band, label):\n",
    "    # Define visualization parameters\n",
    "    vis_params = {\n",
    "        'min': 0.5,\n",
    "        'max': 1.0,\n",
    "        'palette': ['red', 'white', 'green']\n",
    "    }\n",
    "\n",
    "    # Create a map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Center the map on the area of interest\n",
    "    Map.centerObject(aoi, 12)\n",
    "\n",
    "    # Add the mean NDVI layer to the map\n",
    "    Map.addLayer(ic.select(band), vis_params, label)\n",
    "\n",
    "    # Display the map\n",
    "    return Map\n",
    "\n",
    "def get_environmental_data(directory_data, filename,sentinel_vi,sentinel_bands, general):\n",
    "    env_df = pd.read_csv(os.path.join(directory_data, filename), index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "\n",
    "    s2_all = env_df.columns.values.tolist()\n",
    "    s2_all = sorted([item for item in s2_all if not (item.endswith('_residual') or \n",
    "                                                    item.endswith('_trend') or \n",
    "                                                    item.endswith('_season'))])\n",
    "\n",
    "    s2_all = sorted([item for item in s2_all if not (item.startswith('CO2') or \n",
    "                                                    item.startswith('H_') or \n",
    "                                                    item.startswith('LE_'))])\n",
    "\n",
    "    s2_all = [item for item in s2_all if item not in sentinel_vi]\n",
    "    s2_all = [item for item in s2_all if item not in sentinel_bands]\n",
    "    s2_all = [item for item in s2_all if item not in general]\n",
    "\n",
    "    selected_columns = s2_all \n",
    "    env_df = env_df[selected_columns]\n",
    "\n",
    "    return env_df\n",
    "\n",
    "def merge_s2_env_data(s2_df, env_df, expected_columns):\n",
    "    s2_df = s2_df.reset_index()\n",
    "    env_df = env_df.reset_index()\n",
    "    env_df = env_df.rename(columns={'TIMESTAMP':'time'})\n",
    "\n",
    "    df_merged = s2_df.merge(env_df, on=['time'], how='left')\n",
    "    df_merged.set_index(['time','latitude','longitude'], inplace=True)\n",
    "\n",
    "    df_merged = df_merged[expected_columns]\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def predict_gpp(df_merged, model_file):\n",
    "    print('Predicting Gross Primary Production')\n",
    "    loaded_model = XGBRegressor()\n",
    "    loaded_model.load_model(model_file)\n",
    "    y_pred = loaded_model.predict(df_merged)\n",
    "    df_merged['GPP'] = y_pred\n",
    "    ds_gpp = df_merged.to_xarray()\n",
    "    return ds_gpp\n",
    "\n",
    "def plot_save_var(ds, var, netcdf_output, geotif_output):\n",
    "    ds[var].isel(time=0).plot()\n",
    "    crs = CRS.from_epsg(4326) #3857\n",
    "\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "    ds[var].to_netcdf(netcdf_output)\n",
    "\n",
    "    da = ds[var].isel(time=0)\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "    da.rio.to_raster(geotif_output)\n",
    "\n",
    "def sites_info(site_list, directory_data):\n",
    "    df_sites = pd.read_excel(site_list)\n",
    "    df_sites = df_sites.dropna(subset=['deims'])\n",
    "    site_name_list = sorted(df_sites['site name'].values.tolist())\n",
    "    files_list = os.listdir(directory_data)\n",
    "    files_list = sorted([file for file in files_list if any(file.startswith(site_name) for site_name in site_name_list)])\n",
    "\n",
    "    return site_name_list, files_list, df_sites\n",
    "\n",
    "def plot_save_gpp(ds, site, period, directory_maps): \n",
    "    print('Saving Gross Primary Production products\\n')   \n",
    "    crs = CRS.from_epsg(4326)\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "\n",
    "    ds['GPP'].to_netcdf(os.path.join(directory_maps, f'{site} - Gross Primary Production ({period[0]}).nc'))\n",
    "\n",
    "    da = ds['GPP'].isel(time=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    da.plot()\n",
    "    plt.title(f'{site} - Gross Primary Production (GPP) - {period[0]}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site} - Gross Primary Production ({period[0]}).png'))\n",
    "    plt.close()\n",
    "\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    da.rio.to_raster(\n",
    "        os.path.join(directory_maps, f'{site} - Gross Primary Production ({period[0]}).tif'),\n",
    "        driver='COG',\n",
    "        compress='deflate',\n",
    "        nodata=da.attrs.get('_FillValue', None),\n",
    "        dtype=da.dtype.name\n",
    "    )\n",
    "\n",
    "def get_collection_without_clouds(\n",
    "        collection,\n",
    "        year_list,\n",
    "        aoi, \n",
    "        longitude,\n",
    "        latitude,\n",
    "        max_cloud_coverage,\n",
    "        local_cloud_coverage,\n",
    "):\n",
    "    \n",
    "    # function to load data set with specified period and location\n",
    "    def load_catalog(catalog, time, location, bands):\n",
    "        dataset = ee.ImageCollection(catalog).filterDate(time[0],time[1]).filterBounds(location).select(bands)\n",
    "        return dataset\n",
    "\n",
    "    # function to derive VIs\n",
    "    def calculateVI(image):\n",
    "        '''This method calculates different vegetation indices in a image collection and adds their values as new bands'''\n",
    "\n",
    "        # defining dictionary of bands Sentinel-2 \n",
    "        dict_bands = {\n",
    "\n",
    "            \"blue\"  :  'B2',                              #Blue band                        \n",
    "            \"green\" :  'B3',                              #Green band\n",
    "            \"red\"   :  'B4',                              #Red band\n",
    "            \"red1\"  :  'B5',                              #Red-edge spectral band   \n",
    "            \"red2\"  :  'B6',                              #Red-edge spectral band\n",
    "            \"red3\"  :  'B7',                              #Red-edge spectral band    \n",
    "            \"NIR\"   :  'B8',                              #Near-infrared band\n",
    "            \"NIRn\"  :  'B8A',                             #Near-infrared narrow\n",
    "            \"WV\"    :  'B9',                              #Water vapour\n",
    "            \"SWIR1\" :  'B11',                             #Short wave infrared 1\n",
    "            \"SWIR2\" :  'B12',                             #Short wave infrared 2\n",
    "        }\n",
    "\n",
    "        # specify bands \n",
    "        dict  = dict_bands\n",
    "        blue  = dict[\"blue\"]                              #Blue band                        \n",
    "        green = dict[\"green\"]                             #Green band\n",
    "        red   = dict[\"red\"]                               #Red band\n",
    "        red1  = dict[\"red1\"]                              #Red-edge spectral band    \n",
    "        red2  = dict[\"red2\"]                              #Red-edge spectral band\n",
    "        red3  = dict[\"red3\"]                              #Red-edge spectral band\n",
    "        NIR   = dict[\"NIR\"]                               #Near-infrared band\n",
    "        NIRn  = dict[\"NIRn\"]                              #Near-infrared band\n",
    "        WV    = dict[\"WV\"]                                #Water vapour\n",
    "        SWIR1 = dict[\"SWIR1\"]                             #Short wave infrared 1\n",
    "        SWIR2 = dict[\"SWIR2\"]                             #Short wave infrared 2\n",
    "\n",
    "        bands_for_expressions = {\n",
    "\n",
    "            'blue'  : image.select(blue).divide(10000),\n",
    "            'green' : image.select(green).divide(10000), \n",
    "            'red'   : image.select(red).divide(10000),\n",
    "            'red1'  : image.select(red1).divide(10000), \n",
    "            'red2'  : image.select(red2).divide(10000),\n",
    "            'red3'  : image.select(red3).divide(10000), \n",
    "            'NIR'   : image.select(NIR).divide(10000),\n",
    "            'NIRn'  : image.select(NIRn).divide(10000),\n",
    "            'WV'    : image.select(WV).divide(10000),\n",
    "            'SWIR1' : image.select(SWIR1).divide(10000),\n",
    "            'SWIR2' : image.select(SWIR2).divide(10000)}\n",
    "\n",
    "        # greeness related indices\n",
    "        # NDVI                                                                             (Rouse et al., 1974)\n",
    "        NDVI  = image.normalizedDifference([NIR, red]).rename(\"NDVI\") \n",
    "        # EVI                                                                             \n",
    "        EVI   = image.expression('2.5*(( NIR - red ) / ( NIR + 6 * red - 7.5 * blue + 1 ))', \n",
    "                bands_for_expressions).rename(\"EVI\")\n",
    "        # EVI2                                                                             (Jiang et al., 2008)\n",
    "        EVI2  = image.expression('2.5*(( NIR - red ) / ( NIR + 2.4 * red + 1 ))', \n",
    "                bands_for_expressions).rename(\"EVI2\")\n",
    "\n",
    "        # greeness related indices with Sentinel-2 narrow bands / Red-edge\n",
    "        # Clr\n",
    "        CLr  = image.expression('(red3/red1)-1', bands_for_expressions).rename(\"CLr\")\n",
    "        # Clg\n",
    "        Clg  = image.expression('(red3/green)-1', bands_for_expressions).rename(\"CLg\")\n",
    "        # MTCI\n",
    "        MTCI = image.expression('(red2-red1)/(red1-red)', bands_for_expressions).rename(\"MTCI\")\n",
    "        # MNDVI                                                                            (Add reference)\n",
    "        MNDVI = image.normalizedDifference([red3, red1]).rename(\"MNDVI\")    \n",
    "\n",
    "        # water related indices\n",
    "        # MNDWI                                                                            (Add reference)\n",
    "        MNDWI = image.normalizedDifference([green, SWIR1]).rename(\"MNDWI\")    \n",
    "        # NDWI OR LSWI or NDII or NDMI                                                     (Add reference)\n",
    "        LSWI  = image.normalizedDifference([NIR, SWIR1]).rename(\"LSWI\")\n",
    "        # NDII                                                                             (Hunt & Qu, 2013)\n",
    "        NDII   = image.normalizedDifference([NIR, SWIR2]).rename(\"NDII\")\n",
    "\n",
    "        image = image.addBands(NDVI).addBands(EVI).addBands(EVI2)\n",
    "        image = image.addBands(CLr).addBands(Clg).addBands(MTCI).addBands(MNDVI)\n",
    "        image = image.addBands(MNDWI).addBands(LSWI).addBands(NDII)\n",
    "\n",
    "        return image  \n",
    "\n",
    "    # cloud coverage filter function\n",
    "    def cloud_filter(collection, cloud_coverage_metadata_name, threshold):\n",
    "        collection_cf = collection.filterMetadata(cloud_coverage_metadata_name,'less_than', threshold)\n",
    "        # Show messages\n",
    "        print('The maximun cloud coverage in the image is:', max_cloud_coverage)\n",
    "        print('The original size of the collection is', collection.size().getInfo())\n",
    "        # print(s2.first().getInfo())\n",
    "        print('The filtered size of the collection is', collection_cf.size().getInfo(),'\\n')\n",
    "        return collection_cf\n",
    "    \n",
    "    def local_cloud_filter(s2, aoi, LOCAL_CLOUD_THRESH):\n",
    "        # Describe functions\n",
    "        # Function to scale the reflectance bands\n",
    "        def apply_scale_factors_s2(image):\n",
    "            optical_bands = image.select(['B.']).divide(10000)\n",
    "            thermal_bands = image.select(['B.*']).divide(10000)\n",
    "            return image.addBands(optical_bands, None, True).addBands(thermal_bands, None, True)\n",
    "\n",
    "        # Function to create mask with cirrus clouds and cirrus pixels\n",
    "        def extract_bit_s2_10_11(image):\n",
    "            bit_position_clouds = 10\n",
    "            bit_position_cirrus = 11\n",
    "\n",
    "            # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "            cloud_bit_mask = 1 << bit_position_clouds\n",
    "            cirrus_bit_mask = 1 << bit_position_cirrus\n",
    "\n",
    "            mask_clouds = image.bitwiseAnd(cloud_bit_mask).rightShift(bit_position_clouds)\n",
    "            mask_cirrus = image.bitwiseAnd(cirrus_bit_mask).rightShift(bit_position_cirrus)\n",
    "            mask = mask_clouds.add(mask_cirrus)\n",
    "            return mask\n",
    "\n",
    "        # Function to mask pixels with high reflectance in the blue (B2) band. The function creates a QA band\n",
    "        def b2_mask(image):\n",
    "            B2Threshold = 0.2\n",
    "            B2Mask = image.select('B2').gt(B2Threshold)\n",
    "            return image.addBands(B2Mask.rename('B2Mask'))\n",
    "\n",
    "        # Function to create a band with ones\n",
    "        def make_ones(image):\n",
    "            # Create a band with ones\n",
    "            ones_band = image.select('B2').divide(image.select('B2'))\n",
    "            return image.addBands(ones_band.rename('Ones'))\n",
    "\n",
    "        # Function to calculate area\n",
    "        def get_area(img):\n",
    "            cloud_area = make_ones(img).select('Ones').multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=30).values().get(0)\n",
    "            return img.set('area_image', ee.Number(cloud_area))\n",
    "\n",
    "        # Function to get local cloud percentage with QA band\n",
    "        def get_local_cloud_percentage(img):\n",
    "            error_margin = 1 # meter\n",
    "            cloud_area = extract_bit_s2_10_11(img.select('QA60')).multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage', ee.Number(cloud_area).divide(aoi.area(maxError=error_margin)).multiply(100).round())\n",
    "\n",
    "        # Function to get local cloud percentage with QA and area of image band\n",
    "        def get_local_cloud_percentage_area_image(img):\n",
    "            area_image = img.get('area_image')\n",
    "            cloud_area = extract_bit_s2_10_11(img.select('QA60')).multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage_ai', ee.Number(cloud_area).divide(ee.Number(area_image)).multiply(100).round())\n",
    "\n",
    "        # Function to get local cloud percentage with B2 and area of image band\n",
    "        def get_local_cloud_percentage_area_image_b2(img):\n",
    "            area_image = img.get('area_image')\n",
    "            cloud_area = b2_mask(img).select('B2Mask').multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage_ai_b2', ee.Number(cloud_area).divide(ee.Number(area_image)).multiply(100).round())\n",
    "\n",
    "        # def add_ndvi(image):\n",
    "        #     # Calculate NDVI\n",
    "        #     ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        #     return image.addBands(ndvi)\n",
    "\n",
    "        s2 = s2.filterBounds(aoi).map(lambda image: image.clip(aoi)).map(apply_scale_factors_s2) #.map(add_ndvi)\n",
    "        \n",
    "        # Processing\n",
    "        # Calculate area\n",
    "        s2 = s2.map(get_area)\n",
    "        # Calculate local cloud percentage with QA band\n",
    "        s2 = s2.map(get_local_cloud_percentage)\n",
    "        # Calculate local cloud percentage with QA band and area image band\n",
    "        s2 = s2.map(get_local_cloud_percentage_area_image)\n",
    "        # Calculate local cloud percentage with B2 band and area image band\n",
    "        s2 = s2.map(get_local_cloud_percentage_area_image_b2)\n",
    "        # Filter images\n",
    "        s2_filtered = s2.filter(ee.Filter.lte('local_cloud_percentage_ai', LOCAL_CLOUD_THRESH))\n",
    "        s2_filtered = s2_filtered.filter(ee.Filter.lte('local_cloud_percentage_ai_b2', LOCAL_CLOUD_THRESH))\n",
    "\n",
    "        # Show messages\n",
    "        print('The maximun cloud coverage in the area is:', LOCAL_CLOUD_THRESH)\n",
    "        print('The original size of the collection is', s2.size().getInfo())\n",
    "        # print(s2.first().getInfo())\n",
    "        print('The filtered size of the collection is', s2_filtered.size().getInfo(),'\\n')\n",
    "        \n",
    "        return s2_filtered \n",
    "\n",
    "    # function for masking non-vegetation areas\n",
    "    def maskS2nonvegetation(image):\n",
    "\n",
    "            qa    = image.select('QA60')\n",
    "            scl   = image.select('SCL')\n",
    "            ndvi  = image.select('NDVI')\n",
    "            mndvi = image.select('MNDVI')\n",
    "\n",
    "            cloudBitMask = 1 << 10\n",
    "            cirrusBitMask = 1 << 11\n",
    "\n",
    "            #vegetationMask1 = 4 # vegetation\n",
    "            #vegetationMask2 = 5 # non-vegetated\n",
    "            #vegetationMask3 = 6 # water\n",
    "            #vegetationMask4 = 7 # unclassified\n",
    "            #vegetationMask5 = 11 # snow\n",
    "\n",
    "            # this mask selects vegetation + non-vegetated + water + unclassified + areas with VIs (NDVI and MNDVI) greater that a threshold set in the configuration file\n",
    "            mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "            # mask = scl.eq(4).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "            # mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "            vegetation = image.updateMask(mask)\n",
    "\n",
    "            return vegetation\n",
    "    \n",
    "    # get inpu data\n",
    "    # create a only file per year identified in the input files\n",
    "    years = year_list\n",
    "\n",
    "    # create range according to data in the input datafiles   \n",
    "    start   = '%s-01-01'   %(years[0])                                                                                          \n",
    "    end     = '%s-12-31'   %(years[-1])                                            \n",
    "    timeSD  = [start, end]\n",
    "\n",
    "    # create coordinates of the eddy covariance tower\n",
    "    lon_lat =  [longitude, latitude]         \n",
    "    point   = ee.Geometry.Point(lon_lat)\n",
    "\n",
    "    # collections google earth engine    \n",
    "    COPERNICUS_S2_L2A = collection #Multi-spectral surface reflectances (https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR)       \n",
    "    COPERNICUS_S2_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'AOT', 'WVP', 'SCL', 'TCI_R', 'TCI_G', 'TCI_B', 'QA10', 'QA20', 'QA60']\n",
    "\n",
    "    # applying functions \n",
    "    # request of catalogues \n",
    "    S2_VI     = load_catalog(COPERNICUS_S2_L2A, timeSD, point, COPERNICUS_S2_bands)\n",
    "\n",
    "    # filter cloud coverage\n",
    "    cloud_coverage_metadata_name = 'CLOUDY_PIXEL_PERCENTAGE'                     # name of metadata property indicating cloud coverage in %\n",
    "\n",
    "    # applying cloud filter \n",
    "    S2_VI = cloud_filter(S2_VI, cloud_coverage_metadata_name, max_cloud_coverage)   # max cloud coverage defined in the Config file\n",
    "\n",
    "    # apply cloud local filter\n",
    "    S2_VI = local_cloud_filter(S2_VI, aoi, local_cloud_coverage)\n",
    "\n",
    "    # calculation of vegetation indices for the collection\n",
    "    S2_VI = S2_VI.map(calculateVI)\n",
    "\n",
    "    # applying mask \n",
    "    S2_VI = S2_VI.map(maskS2nonvegetation)\n",
    "\n",
    "    return S2_VI, point\n",
    "\n",
    "def get_ecosystem_geometry(training_dataset,number_clusters,training_scale,scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent):\n",
    "    #https://code.earthengine.google.com/2b95fd6462c6c906d4ed9a74fae51bf4\n",
    "    Region    =  point.buffer(ecosystem_extent/2)\n",
    "    inputML   =  ic.select(bands).median().clip(Region)\n",
    "\n",
    "    # This trainning function takes pixes or pixels even in larger region than inputML\n",
    "    training  = inputML.sample(region=Region, scale=training_scale, numPixels=training_dataset)\n",
    "    clusterer = ee.Clusterer.wekaKMeans(number_clusters).train(training)\n",
    "\n",
    "    result    = inputML.cluster(clusterer)\n",
    "    results_colect  = ee.ImageCollection([result])\n",
    "    df_clus = results_colect.getRegion(point, scale_getRegion).getInfo()\n",
    "    df_clus = pd.DataFrame(df_clus)\n",
    "    headers = df_clus.iloc[0]\n",
    "    df_clus = pd.DataFrame(df_clus.values[1:], columns=headers).set_index('id')\n",
    "    cluster_ecosystem = df_clus['cluster'][0]\n",
    "    results_shp = result.reduceToVectors(scale=vector_scale, bestEffort=True)\n",
    "\n",
    "    def classification(weka, num):\n",
    "        class_vegetation = weka.select('label').filter(ee.Filter.eq('label', num))\n",
    "        return class_vegetation\n",
    "\n",
    "    cluster_name = []\n",
    "    for i in range(number_clusters):\n",
    "        globals()['cluster_%s'%i] = classification(results_shp, i).union(1).geometry()\n",
    "        cluster_name.append(globals()['cluster_%s'%i])\n",
    "\n",
    "    cluster_ecosystem_geometry  = cluster_name[cluster_ecosystem]\n",
    "\n",
    "    et_image = ee.ImageCollection([result.eq(cluster_ecosystem)])\n",
    "\n",
    "    return inputML, et_image, cluster_ecosystem_geometry \n",
    "\n",
    "def get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year):\n",
    "    # define a method for displaying Earth Engine image tiles on a folium map.\n",
    "    def add_ee_layer(self, ee_object, vis_params, name):\n",
    "        try:    \n",
    "\n",
    "            # display ee.Image()\n",
    "            if isinstance(ee_object, ee.image.Image):    \n",
    "                map_id_dict = ee.Image(ee_object).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "                ).add_to(self)\n",
    "\n",
    "            # display ee.ImageCollection()\n",
    "            elif isinstance(ee_object, ee.imagecollection.ImageCollection):    \n",
    "                ee_object_new = ee_object.mosaic()\n",
    "                map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "                ).add_to(self)\n",
    "\n",
    "            # display ee.Geometry()\n",
    "            elif isinstance(ee_object, ee.geometry.Geometry):    \n",
    "                folium.GeoJson(\n",
    "                data = ee_object.getInfo(),\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True,\n",
    "                style_function=lambda x:vis_params\n",
    "            ).add_to(self)\n",
    "\n",
    "            # display ee.FeatureCollection()\n",
    "            elif isinstance(ee_object, ee.featurecollection.FeatureCollection):  \n",
    "                ee_object_new = ee.Image().paint(ee_object, 0, 2)\n",
    "                map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "            ).add_to(self)\n",
    "\n",
    "        except:\n",
    "            print(\"Could not display {}\".format(name))\n",
    "\n",
    "    # add EE drawing method to folium.\n",
    "    folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "    # Add custom basemaps to folium\n",
    "    basemaps = {\n",
    "        'Google Maps': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Maps',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Satellite': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Terrain': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=p&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Terrain',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Satellite Hybrid': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Esri Satellite': folium.TileLayer(\n",
    "            tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "            attr = 'Esri',\n",
    "            name = 'Esri Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "    # Mapping with folium\n",
    "    # a) create a folium map object.\n",
    "    my_map = folium.Map(location= [latitude,longitude], zoom_start=12)\n",
    "    # b) add custom basemaps\n",
    "    basemaps['Esri Satellite'].add_to(my_map)\n",
    "    basemaps['Google Satellite Hybrid'].add_to(my_map)\n",
    "    # c) set visualization parameters.\n",
    "    vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 4000,\n",
    "    'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}\n",
    "    # d) display Geometry\n",
    "    vis_params_geometry = dict(color='red', weight=2, opacity=10, fillColor='red')\n",
    "    my_map.add_ee_layer(cluster_ecosystem_geometry,  vis_params_geometry , 'Ecosystem area')\n",
    "    # d) display ee.Image\n",
    "    dataset        = inputML.select('NDVI')\n",
    "    vis_params = {\n",
    "        'min': 0.5,\n",
    "        'max': 1.0,\n",
    "        'palette': ['red', 'white', 'green']\n",
    "    }\n",
    "    my_map.add_ee_layer(dataset, vis_params, 'NDVI')\n",
    "    # e) add a layer control panel to the map.\n",
    "    my_map.add_child(folium.LayerControl())\n",
    "    plugins.Fullscreen().add_to(my_map)\n",
    "    \n",
    "    my_map.save(os.path.join(directory_maps, f'{site} - Ecosystem map ({year}).html'))\n",
    "    return my_map\n",
    "\n",
    "def get_et_df(et_array, year):\n",
    "    df = pd.DataFrame(et_array[1:], columns=et_array[0])\n",
    "    df = df.iloc[:,1:]\n",
    "    df['time'] =  pd.to_datetime(f'{year}')\n",
    "    df.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def plot_save_et(image, aoi, site, year, directory_maps, mse, test_r2, mae, rmse): \n",
    "    print(f'Saving Uncertainty product for {year}\\n')   \n",
    "\n",
    "    et_sample = image.getRegion(aoi, 10).getInfo()\n",
    "    df_et =  get_et_df(et_sample, year)\n",
    "    ds = df_et.to_xarray()\n",
    "\n",
    "    crs = CRS.from_epsg(4326)\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "    ds.attrs['title'] = f'Gross Primary Production Uncertainty Map - {year}'\n",
    "    ds.attrs['description'] = 'This COG file represents the uncertainty in Gross Primary Production estimates for the specified year.'\n",
    "    ds.attrs['source'] = site\n",
    "    ds.attrs['year'] = year\n",
    "    ds.attrs['MSE'] = mse\n",
    "    ds.attrs['MAE'] = mae\n",
    "    ds.attrs['RMSE'] = rmse\n",
    "    ds.attrs['R^2'] = test_r2\n",
    "\n",
    "    ds['cluster'].to_netcdf(os.path.join(directory_maps, f'{site} - Gross Primary Production Uncertainty Map ({year}).nc'))\n",
    "\n",
    "    da = ds['cluster'].isel(time=0)\n",
    "    da.attrs['crs'] = crs.to_string()\n",
    "    da.attrs['title'] = f'Gross Primary Production Uncertainty Map - {year}'\n",
    "    da.attrs['description'] = 'This COG file represents the uncertainty in Gross Primary Production estimates for the specified year.'\n",
    "    da.attrs['source'] = site\n",
    "    da.attrs['year'] = year\n",
    "    da.attrs['MSE'] = mse\n",
    "    da.attrs['MAE'] = mae\n",
    "    da.attrs['RMSE'] = rmse\n",
    "    da.attrs['R^2'] = test_r2\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    da.plot()\n",
    "    plt.title(f'{site} - Gross Primary Production (GPP) - Uncertainty Map - {year}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site} - Gross Primary Production Uncertainty Map ({year}).png'))\n",
    "    plt.close()\n",
    "\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    da.rio.to_raster(\n",
    "        os.path.join(directory_maps, f'{site} - Gross Primary Production Uncertainty Map ({year}).tif'),\n",
    "        driver='COG',\n",
    "        compress='deflate',\n",
    "        nodata=da.attrs.get('_FillValue', None),\n",
    "        dtype=da.dtype.name\n",
    "    )\n",
    "\n",
    "def get_testing_data(directory_data, filename, expected_columns, gpp_column):\n",
    "    env_df = pd.read_csv(os.path.join(directory_data, filename), index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "    env_testing = env_df[expected_columns]\n",
    "    gpp_testing = env_df[gpp_column]\n",
    "    return env_testing, gpp_testing\n",
    "\n",
    "def predict_gpp_df(df, model_file):\n",
    "    print('Testing Gross Primary Production')\n",
    "    loaded_model = XGBRegressor()\n",
    "    loaded_model.load_model(model_file)\n",
    "    y_pred = loaded_model.predict(df)\n",
    "    df['GPP_predicted'] = y_pred\n",
    "    return df\n",
    "\n",
    "def get_performance(df, year):\n",
    "    df = df.reset_index()\n",
    "    df = df[df['TIMESTAMP'].dt.year == int(year)]\n",
    "    y_test = df['GPP_testing']\n",
    "    y_pred = df['GPP_predicted']\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('Root Mean Squared Error:', rmse)\n",
    "    print('MAE:', mae)\n",
    "    print(\"Test R^2 Score:\", test_r2,'\\n')\n",
    "\n",
    "    return df, mse, test_r2, mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "site_list = r'D:\\Proyectos2024\\Agame\\Repository\\vlabs\\sen2gpp\\Input\\list_sites_icos.xlsx'\n",
    "model_file = r\"D:\\Proyectos2024\\Agame\\Repository\\vlabs\\sen2gpp\\Output\\Model\\xgboost_model_all_nogeneral.json\"\n",
    "directory_data = r'D:\\Proyectos2024\\Agame\\Repository\\vlabs\\sen2gpp\\Output\\Tables'\n",
    "directory_maps = r'D:\\Proyectos2024\\Agame\\Repository\\vlabs\\sen2gpp\\Output\\Maps'\n",
    "\n",
    "sentinel_vi = ['CLr','EVI','EVI2','LSWI', 'MNDVI','MNDWI','NDII','NDVI']\n",
    "sentinel_bands  = ['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B11','B12']\n",
    "general = ['latitude', 'longitude', 'elevation', 'canopy_height', 'biom_croplands', 'biom_dbf', 'biom_enf', 'biom_grasslands', 'winter','spring', 'summer', 'fall']\n",
    "expected_columns = ['CLr', 'DAY_D', 'DAY_RANDUNC_N', 'EBC_CF_N', 'EVI', 'EVI2', 'G_F_MDS', 'LSWI', 'LW_IN_ERA', 'LW_IN_F', 'LW_IN_F_MDS', 'LW_IN_JSB', 'LW_IN_JSB_ERA', 'LW_IN_JSB_F', 'LW_OUT', 'MNDVI', 'MNDWI', 'NDII', 'NDVI', 'NETRAD', 'NIGHT_D', 'NIGHT_RANDUNC_N', 'PA_ERA', 'PA_F', 'PPFD_IN', 'PPFD_OUT', 'P_ERA', 'P_F', 'SWC_F_MDS_1', 'SWC_F_MDS_2', 'SW_IN_ERA', 'SW_IN_F', 'SW_IN_F_MDS', 'SW_IN_POT', 'SW_OUT', 'TA_ERA', 'TA_ERA_DAY', 'TA_ERA_DAY_SD', 'TA_ERA_NIGHT', 'TA_ERA_NIGHT_SD', 'TA_F', 'TA_F_DAY', 'TA_F_DAY_SD', 'TA_F_MDS', 'TA_F_MDS_DAY', 'TA_F_MDS_DAY_SD', 'TA_F_MDS_NIGHT', 'TA_F_MDS_NIGHT_SD', 'TA_F_NIGHT', 'TA_F_NIGHT_SD', 'TS_F_MDS_1', 'TS_F_MDS_2', 'TS_F_MDS_3', 'USTAR', 'VPD_ERA', 'VPD_F', 'VPD_F_MDS', 'WS_ERA', 'WS_F', 'day', 'month']\n",
    "# date_range_values = ['2022-11-07','2023-12-31']\n",
    "\n",
    "date_range_values = ['2021-10-26','2021-12-31'] \n",
    "\n",
    "# MGRS_TILE = '34VFP' #'35VLJ'\n",
    "MGRS_TILE = None\n",
    "\n",
    "max_cloud_coverage   = 100\n",
    "local_cloud_coverage = 0\n",
    "training_dataset = 10000\n",
    "number_clusters = 2 # Torgnon = 3\n",
    "training_scale = 10\n",
    "scale_getRegion = 10\n",
    "vector_scale = 10\n",
    "ecosystem_extent = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "site_name_list, files_list, df_sites = sites_info(site_list, directory_data)\n",
    "site_name_list = site_name_list[2:3]\n",
    "files_list = files_list[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country code</th>\n",
       "      <th>site name</th>\n",
       "      <th>station id</th>\n",
       "      <th>main ecosystem</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>canopy_height</th>\n",
       "      <th>instrument_height</th>\n",
       "      <th>fetch_desired</th>\n",
       "      <th>status</th>\n",
       "      <th>snow_season</th>\n",
       "      <th>role</th>\n",
       "      <th>deims</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>Hohes Holz</td>\n",
       "      <td>DE-HoH</td>\n",
       "      <td>dbf</td>\n",
       "      <td>52.08656</td>\n",
       "      <td>11.222350</td>\n",
       "      <td>193</td>\n",
       "      <td>33.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>500</td>\n",
       "      <td>Snow coverage for some years (e.g. 2020)</td>\n",
       "      <td>dec-jan</td>\n",
       "      <td>training</td>\n",
       "      <td>https://deims.org/ddd2e8d2-44db-420e-8fa4-6b4f...</td>\n",
       "      <td>https://meta.icos-cp.eu/resources/stations/ES_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT</td>\n",
       "      <td>Torgnon</td>\n",
       "      <td>IT-Tor</td>\n",
       "      <td>grasslands</td>\n",
       "      <td>45.84444</td>\n",
       "      <td>7.578055</td>\n",
       "      <td>2168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>80</td>\n",
       "      <td>High snow coverage</td>\n",
       "      <td>nov-may</td>\n",
       "      <td>training</td>\n",
       "      <td>https://deims.org/a03ef869-aa6f-49cf-8e86-f791...</td>\n",
       "      <td>https://meta.icos-cp.eu/resources/stations/ES_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FI</td>\n",
       "      <td>Hyytiala</td>\n",
       "      <td>FI-Hyy</td>\n",
       "      <td>enf</td>\n",
       "      <td>61.84741</td>\n",
       "      <td>24.294770</td>\n",
       "      <td>181</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>400</td>\n",
       "      <td>High snow coverage</td>\n",
       "      <td>jan-apr</td>\n",
       "      <td>training</td>\n",
       "      <td>https://deims.org/663dac80-211d-4c19-a356-04ee...</td>\n",
       "      <td>https://meta.icos-cp.eu/resources/stations/ES_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SE</td>\n",
       "      <td>Svartberget</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>enf</td>\n",
       "      <td>64.25611</td>\n",
       "      <td>19.774500</td>\n",
       "      <td>267</td>\n",
       "      <td>28.8</td>\n",
       "      <td>34.50</td>\n",
       "      <td>700</td>\n",
       "      <td>Maximun canopy height of tree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>testing</td>\n",
       "      <td>https://deims.org/c0705d0f-92c1-4964-a345-38c0...</td>\n",
       "      <td>https://meta.icos-cp.eu/resources/stations/ES_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country code    site name station id main ecosystem  latitude  longitude  \\\n",
       "1           DE   Hohes Holz     DE-HoH            dbf  52.08656  11.222350   \n",
       "2           IT      Torgnon     IT-Tor     grasslands  45.84444   7.578055   \n",
       "3           FI     Hyytiala     FI-Hyy            enf  61.84741  24.294770   \n",
       "6           SE  Svartberget     SE-Svb            enf  64.25611  19.774500   \n",
       "\n",
       "   elevation  canopy_height  instrument_height  fetch_desired  \\\n",
       "1        193           33.0              45.00            500   \n",
       "2       2168            0.0               2.55             80   \n",
       "3        181           18.0              27.00            400   \n",
       "6        267           28.8              34.50            700   \n",
       "\n",
       "                                     status snow_season      role  \\\n",
       "1  Snow coverage for some years (e.g. 2020)     dec-jan  training   \n",
       "2                        High snow coverage     nov-may  training   \n",
       "3                        High snow coverage     jan-apr  training   \n",
       "6             Maximun canopy height of tree         NaN   testing   \n",
       "\n",
       "                                               deims  \\\n",
       "1  https://deims.org/ddd2e8d2-44db-420e-8fa4-6b4f...   \n",
       "2  https://deims.org/a03ef869-aa6f-49cf-8e86-f791...   \n",
       "3  https://deims.org/663dac80-211d-4c19-a356-04ee...   \n",
       "6  https://deims.org/c0705d0f-92c1-4964-a345-38c0...   \n",
       "\n",
       "                                         Unnamed: 14  \n",
       "1  https://meta.icos-cp.eu/resources/stations/ES_...  \n",
       "2  https://meta.icos-cp.eu/resources/stations/ES_...  \n",
       "3  https://meta.icos-cp.eu/resources/stations/ES_...  \n",
       "6  https://meta.icos-cp.eu/resources/stations/ES_...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating products for Svartberget\n",
      "\n",
      "The area of the site is 67340866.87546413 square meters\n",
      "The area of the site is 67.34086687546413 square kilometers\n",
      "The site geometry is ready to extract Earth Observation data\n",
      "\n",
      "Testing Gross Primary Production\n",
      "Period: 2021-10-26, 2021-10-27\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211026T103131_20211026T103127_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-10-27, 2021-10-28\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-10-28, 2021-10-29\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211028T102039_20211028T102038_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-10-29, 2021-10-30\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-10-30, 2021-10-31\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211030T101141_20211030T101141_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-10-31, 2021-11-01\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211031T103059_20211031T103059_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-01, 2021-11-02\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-02, 2021-11-03\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211102T102201_20211102T102203_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-03, 2021-11-04\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-04, 2021-11-05\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211104T101109_20211104T101112_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-05, 2021-11-06\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211105T103221_20211105T103224_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-06, 2021-11-07\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-07, 2021-11-08\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211107T102129_20211107T102157_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-08, 2021-11-09\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-09, 2021-11-10\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-10, 2021-11-11\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211110T103149_20211110T103152_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-11, 2021-11-12\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-12, 2021-11-13\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-13, 2021-11-14\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-14, 2021-11-15\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211114T101159_20211114T101201_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-15, 2021-11-16\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-16, 2021-11-17\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-17, 2021-11-18\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211117T102219_20211117T102218_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-18, 2021-11-19\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-19, 2021-11-20\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-20, 2021-11-21\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211120T103239_20211120T103234_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-21, 2021-11-22\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-22, 2021-11-23\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-23, 2021-11-24\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-24, 2021-11-25\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20211124T101239_20211124T101240_T34WDS']\n",
      "Earth Engine Exception: ImageCollection.getRegion: Too many values: 1553365 points x 8 bands x 1 images > 1048576.\n",
      "\n",
      "Period: 2021-11-25, 2021-11-26\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-26, 2021-11-27\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-27, 2021-11-28\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-28, 2021-11-29\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-29, 2021-11-30\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-11-30, 2021-12-01\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-01, 2021-12-02\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-02, 2021-12-03\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-03, 2021-12-04\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-04, 2021-12-05\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-05, 2021-12-06\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-06, 2021-12-07\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-07, 2021-12-08\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-08, 2021-12-09\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-09, 2021-12-10\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-10, 2021-12-11\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-11, 2021-12-12\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-12, 2021-12-13\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-13, 2021-12-14\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-14, 2021-12-15\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-15, 2021-12-16\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-16, 2021-12-17\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-17, 2021-12-18\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-18, 2021-12-19\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-19, 2021-12-20\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-20, 2021-12-21\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-21, 2021-12-22\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-22, 2021-12-23\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-23, 2021-12-24\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-24, 2021-12-25\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-25, 2021-12-26\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-26, 2021-12-27\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-27, 2021-12-28\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-28, 2021-12-29\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-29, 2021-12-30\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-12-30, 2021-12-31\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Calculating uncerstainty product for Svartberget in 2021\n",
      "\n",
      "Mean Squared Error: 1.4309382549561525\n",
      "Root Mean Squared Error: 1.1962183140865854\n",
      "MAE: 0.7484785650114003\n",
      "Test R^2 Score: 0.8833751978786579 \n",
      "\n",
      "The maximun cloud coverage in the image is: 100\n",
      "The original size of the collection is 179\n",
      "The filtered size of the collection is 178 \n",
      "\n",
      "The maximun cloud coverage in the area is: 0\n",
      "The original size of the collection is 178\n",
      "The filtered size of the collection is 12 \n",
      "\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "User memory limit exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\data.py:402\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine-highvolume.googleapis.com/v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"User memory limit exceeded.\". Details: \"User memory limit exceeded.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m ic, point \u001b[38;5;241m=\u001b[39m get_collection_without_clouds(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOPERNICUS/S2_SR_HARMONIZED\u001b[39m\u001b[38;5;124m'\u001b[39m,[year],aoi,longitude,latitude,max_cloud_coverage,local_cloud_coverage)\n\u001b[0;32m     45\u001b[0m bands \u001b[38;5;241m=\u001b[39m ic\u001b[38;5;241m.\u001b[39mfirst()\u001b[38;5;241m.\u001b[39mbandNames()\u001b[38;5;241m.\u001b[39mgetInfo() \n\u001b[1;32m---> 46\u001b[0m inputML, cluster_ecosystem_image, cluster_ecosystem_geometry \u001b[38;5;241m=\u001b[39m \u001b[43mget_ecosystem_geometry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumber_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscale_getRegion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mecosystem_extent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m ecosystem_map \u001b[38;5;241m=\u001b[39m get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Map = map_image(cluster_ecosystem_image.first(), aoi, \"cluster\", \"Cluster\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 700\u001b[0m, in \u001b[0;36mget_ecosystem_geometry\u001b[1;34m(training_dataset, number_clusters, training_scale, scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent)\u001b[0m\n\u001b[0;32m    698\u001b[0m result    \u001b[38;5;241m=\u001b[39m inputML\u001b[38;5;241m.\u001b[39mcluster(clusterer)\n\u001b[0;32m    699\u001b[0m results_colect  \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mImageCollection([result])\n\u001b[1;32m--> 700\u001b[0m df_clus \u001b[38;5;241m=\u001b[39m \u001b[43mresults_colect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetRegion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_getRegion\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    701\u001b[0m df_clus \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df_clus)\n\u001b[0;32m    702\u001b[0m headers \u001b[38;5;241m=\u001b[39m df_clus\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\data.py:1101\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   1098\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[0;32m   1099\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[1;32m-> 1101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\data.py:404\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 404\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[1;31mEEException\u001b[0m: User memory limit exceeded."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for index in range(len(site_name_list)):\n",
    "\n",
    "    print(f'Calculating products for {site_name_list[index]}\\n')\n",
    "\n",
    "    site = site_name_list[index]\n",
    "    filename = files_list[index]\n",
    "    \n",
    "    boundaries, latitude, longitude, information = get_coordinates_area(df_sites, site)\n",
    "    m = map_coordinates_area(df_sites, boundaries, site)\n",
    "    Map, aoi = get_gee_area_from_gpp_multipolygon_single_polygon(boundaries, 6)\n",
    "\n",
    "    date_range = pd.date_range(start=date_range_values[0], end=date_range_values[1], freq='D')\n",
    "    dates_list = date_range.strftime('%Y-%m-%d').tolist()\n",
    "    year_list = get_unique_years(dates_list)\n",
    "\n",
    "    env_testing, gpp_testing = get_testing_data(directory_data, filename, expected_columns, 'GPP_DT_VUT_USTAR50')\n",
    "    gpp_predicted = predict_gpp_df(env_testing, model_file)\n",
    "    gpp_predicted['GPP_testing'] = gpp_testing \n",
    "\n",
    "    for index in range(len(dates_list)-1):\n",
    "        period = [dates_list[index], dates_list[index+1]]\n",
    "        print(f\"Period: {dates_list[index]}, {dates_list[index+1]}\")\n",
    "        \n",
    "        try:\n",
    "            s2_array, s2 = get_s2_array(period,aoi,sentinel_vi,MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "            s2_df = get_s2_df(s2_array)\n",
    "            env_df = get_environmental_data(directory_data,filename,sentinel_vi,sentinel_bands, general)\n",
    "            df_merged = merge_s2_env_data(s2_df, env_df, expected_columns)\n",
    "            ds_gpp = predict_gpp(df_merged, model_file)\n",
    "            plot_save_gpp(ds_gpp, site, period, directory_maps)\n",
    "\n",
    "        except ee.EEException as ee_error:\n",
    "            print(f\"Earth Engine Exception: {ee_error}\\n\")\n",
    "\n",
    "    for year in year_list:\n",
    "        print(f'Calculating uncerstainty product for {site} in {year}\\n')\n",
    "\n",
    "        df, mse, test_r2, mae, rmse = get_performance(gpp_predicted, year)\n",
    "\n",
    "        ic, point = get_collection_without_clouds('COPERNICUS/S2_SR_HARMONIZED',[year],aoi,longitude,latitude,max_cloud_coverage,local_cloud_coverage)\n",
    "        bands = ic.first().bandNames().getInfo() \n",
    "        inputML, cluster_ecosystem_image, cluster_ecosystem_geometry = get_ecosystem_geometry(training_dataset,number_clusters,training_scale,scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent)\n",
    "        ecosystem_map = get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year)\n",
    "        # Map = map_image(cluster_ecosystem_image.first(), aoi, \"cluster\", \"Cluster\")\n",
    "        plot_save_et(cluster_ecosystem_image,aoi, site, year, directory_maps, mse, test_r2, mae, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the folder containing the files\n",
    "folder_path = r'D:\\Proyectos2024\\Agame\\Repository\\vlabs\\sen2gpp\\Output\\Maps\\Torgnon - Gross Primary Production (2021 - 2023)'\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.tif'):\n",
    "        # Extract the initial part and the date\n",
    "        match = re.match(r'Torgnon - Gross Primary Production \\((\\d{4})-(\\d{2})-(\\d{2})\\)\\.tif', filename)\n",
    "        if match:\n",
    "            # Extract the date components\n",
    "            year, month, day = match.groups()\n",
    "            # Create the new filename\n",
    "            new_filename = f'Torgnon_gpp_{year}{month}{day}.tif'\n",
    "            # Get the full paths\n",
    "            old_file = os.path.join(folder_path, filename)\n",
    "            new_file = os.path.join(folder_path, new_filename)\n",
    "            # Rename the file\n",
    "            os.rename(old_file, new_file)\n",
    "            print(f'Renamed: {old_file} -> {new_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deltares_GPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
