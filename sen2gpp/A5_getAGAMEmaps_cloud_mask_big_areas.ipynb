{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGAME Workflow. Get AGAME maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deims\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import ee\n",
    "import xarray\n",
    "import geemap\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "from xgboost import XGBRegressor\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import Polygon, box\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_unique_years(date_range_values):\n",
    "    unique_years = set()\n",
    "    for date in date_range_values:\n",
    "        year = date.split('-')[0] \n",
    "        unique_years.add(year)    \n",
    "\n",
    "    unique_years = sorted(unique_years)\n",
    "\n",
    "    return unique_years\n",
    "\n",
    "def get_coordinates_area(df, site):\n",
    "    site_url = df['deims'].loc[df['sites_ids'] == site].values[0]\n",
    "    latitude  = df['lat'].loc[df['sites_ids'] == site].values[0]\n",
    "    longitude = df['lon'].loc[df['sites_ids'] == site].values[0]\n",
    "    if pd.isna(site_url):\n",
    "        raise ValueError(\"The site DEIMS url is empty. Please provide a valid site URL.\")\n",
    "    else:\n",
    "        boundaries   = deims.getSiteBoundaries([site_url])\n",
    "        information = deims.getSiteById(site_id=site_url)\n",
    "    return boundaries, latitude, longitude, information\n",
    "\n",
    "def map_coordinates_area(df, boundaries, site):\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(df.lon, df.lat),\n",
    "        crs=\"EPSG:3857\"\n",
    "    )\n",
    "    gdf = gdf.loc[gdf['sites_ids'] == site]\n",
    "    centroid = gdf.geometry.centroid.union_all()\n",
    "    m = folium.Map(location=[centroid.y, centroid.x], zoom_start=12)\n",
    "    for idx, row in gdf.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            popup=row['sites_ids']\n",
    "        ).add_to(m)\n",
    "\n",
    "    folium.GeoJson(boundaries).add_to(m)\n",
    "\n",
    "    return m, gdf\n",
    "\n",
    "def get_gee_area(boundaries):\n",
    "    total_bounds = boundaries.total_bounds\n",
    "    aoi = ee.Geometry.Rectangle([total_bounds[0], total_bounds[1], total_bounds[2], total_bounds[3]])\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 10)\n",
    "\n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp(polygon_gdf):\n",
    "    # Ensure the GeoDataFrame contains a valid geometry column\n",
    "    if polygon_gdf.empty or polygon_gdf.geom_type.iloc[0] != 'Polygon':\n",
    "        raise ValueError(\"GeoDataFrame is empty or does not contain Polygon geometries.\")\n",
    "    \n",
    "    # Get the first polygon from the GeoDataFrame\n",
    "    polygon = polygon_gdf.geometry.iloc[0]\n",
    "\n",
    "    # Convert the Shapely Polygon to GeoJSON-like dict\n",
    "    geojson = mapping(polygon)\n",
    "    \n",
    "    # Create an Earth Engine Geometry from the GeoJSON\n",
    "    aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp_multipolygon(geodf):\n",
    "    \n",
    "    if geodf.empty:\n",
    "        raise ValueError(\"GeoDataFrame is empty.\")\n",
    "    \n",
    "    # Get the first geometry from the GeoDataFrame\n",
    "    geom = geodf.geometry.iloc[0]\n",
    "\n",
    "    # Check the geometry type\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geojson = mapping(geom)\n",
    "        aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        # Convert each Polygon in the MultiPolygon to GeoJSON and create ee.Geometry.MultiPolygon\n",
    "        geojson = mapping(geom)\n",
    "        polygons = [ee.Geometry.Polygon(polygon) for polygon in geojson['coordinates']]\n",
    "        aoi = ee.Geometry.MultiPolygon(polygons)\n",
    "        # aoi = ee.Geometry.Polygon(polygons[0])\n",
    "    else:\n",
    "        raise ValueError(\"GeoDataFrame contains unsupported geometry type. Only Polygon and MultiPolygon are supported.\")\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, 'Bounding Box')\n",
    "\n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def get_gee_area_from_gpp_multipolygon_single_polygon(geodf, gdf, num_polygon):\n",
    "        \n",
    "    # Get the first geometry from the GeoDataFrame\n",
    "    if not geodf.empty:    \n",
    "        geom = geodf.geometry.iloc[0]\n",
    "    else:\n",
    "        geom = gdf.geometry.iloc[0]\n",
    "\n",
    "    # Check the geometry type\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geojson = mapping(geom)\n",
    "        aoi = ee.Geometry.Polygon(geojson['coordinates'])\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        # Convert each Polygon in the MultiPolygon to GeoJSON and create ee.Geometry.MultiPolygon\n",
    "        geojson = mapping(geom)\n",
    "        first_polygon_coords = geojson['coordinates'][num_polygon]\n",
    "        polygon = Polygon(first_polygon_coords[0]) \n",
    "        geojson_polygon = polygon.__geo_interface__\n",
    "        aoi = ee.Geometry.Polygon(geojson_polygon['coordinates'])\n",
    "    elif geom.geom_type == 'Point':\n",
    "        print(f\"The deims site does not have ecosystem boundaries. An area of 1 square kilometer will be created with centroid in the ecosystem's longitude and latitude\")\n",
    "        longitude = geom.x\n",
    "        latitude = geom.y\n",
    "        gee_point = ee.Geometry.Point([longitude, latitude])\n",
    "        buffer = gee_point.buffer(500) \n",
    "        aoi = buffer.bounds()\n",
    "    else:\n",
    "        raise ValueError(\"GeoDataFrame contains unsupported geometry type. Only Polygon and MultiPolygon are supported.\")\n",
    "    \n",
    "    error_margin = 1  # meter\n",
    "    area_m2 = aoi.area(maxError=error_margin).getInfo()\n",
    "    area_km2 = area_m2 / 1e6\n",
    "    print(f\"The area of the site is {area_m2} square meters\")\n",
    "    print(f\"The area of the site is {area_km2} square kilometers\\n\")\n",
    "\n",
    "    # Initialize the geemap Map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Add the rectangle to the map\n",
    "    Map.addLayer(aoi, {}, \"Site's area\")\n",
    "\n",
    "    if geom.geom_type != 'Point' and area_km2 < 1:\n",
    "        print(f\"The area of the site is below 1 square kilometer. A new area with a minimun of 1 square kilometer will be created\")\n",
    "        centroid = aoi.centroid()\n",
    "        buffer = centroid.buffer(500)\n",
    "        aoi = buffer.bounds()\n",
    "        error_margin = 1  # meter\n",
    "        area_m2 = aoi.area(maxError=error_margin).getInfo()\n",
    "        area_km2 = area_m2 / 1e6\n",
    "        print(f\"The new area of the site is {area_m2} square meters\")\n",
    "        print(f\"The mew area of the site is {area_km2} square kilometers\")\n",
    "        Map.addLayer(aoi, {}, \"New site's area\")\n",
    "\n",
    "    if geom.geom_type != 'Point' and area_km2 > 25:\n",
    "        print(f\"The area of the site is higher than 25 square kilometer. A new area with a maximun of 25 square kilometer will be created\")\n",
    "        centroid = aoi.centroid()\n",
    "        buffer = centroid.buffer(2500)\n",
    "        aoi = buffer.bounds()\n",
    "        error_margin = 1  # meter\n",
    "        area_m2 = aoi.area(maxError=error_margin).getInfo()\n",
    "        area_km2 = area_m2 / 1e6\n",
    "        print(f\"The new area of the site is {area_m2} square meters\")\n",
    "        print(f\"The mew area of the site is {area_km2} square kilometers\")\n",
    "        Map.addLayer(aoi, {}, \"New site's area\")\n",
    "        \n",
    "    # Center the map around the bounding box\n",
    "    Map.centerObject(aoi, 15)\n",
    "\n",
    "    print(f\"The site geometry is ready to extract Earth Observation data\\n\")\n",
    "    \n",
    "    return Map, aoi\n",
    "\n",
    "def apply_scale_factors_s2(image):\n",
    "    optical_bands = image.select(['B.']).divide(10000)\n",
    "    thermal_bands = image.select(['B.*']).divide(10000)\n",
    "    return image.addBands(optical_bands, None, True).addBands(thermal_bands, None, True)\n",
    "\n",
    "def apply_scale_factors_e5(image):\n",
    "    image = image.divide(24*60*60)\n",
    "    return image\n",
    "\n",
    "# function to derive VIs\n",
    "def calculateVI(image):\n",
    "    '''This method calculates different vegetation indices in a image collection and adds their values as new bands'''\n",
    "\n",
    "    # defining dictionary of bands Sentinel-2 \n",
    "    dict_bands = {\n",
    "\n",
    "        \"blue\"  :  'B2',                              #Blue band                        \n",
    "        \"green\" :  'B3',                              #Green band\n",
    "        \"red\"   :  'B4',                              #Red band\n",
    "        \"red1\"  :  'B5',                              #Red-edge spectral band   \n",
    "        \"red2\"  :  'B6',                              #Red-edge spectral band\n",
    "        \"red3\"  :  'B7',                              #Red-edge spectral band    \n",
    "        \"NIR\"   :  'B8',                              #Near-infrared band\n",
    "        \"NIRn\"  :  'B8A',                             #Near-infrared narrow\n",
    "        \"WV\"    :  'B9',                              #Water vapour\n",
    "        \"SWIR1\" :  'B11',                             #Short wave infrared 1\n",
    "        \"SWIR2\" :  'B12',                             #Short wave infrared 2\n",
    "    }\n",
    "\n",
    "    # specify bands \n",
    "    dict  = dict_bands\n",
    "    blue  = dict[\"blue\"]                              #Blue band                        \n",
    "    green = dict[\"green\"]                             #Green band\n",
    "    red   = dict[\"red\"]                               #Red band\n",
    "    red1  = dict[\"red1\"]                              #Red-edge spectral band    \n",
    "    red2  = dict[\"red2\"]                              #Red-edge spectral band\n",
    "    red3  = dict[\"red3\"]                              #Red-edge spectral band\n",
    "    NIR   = dict[\"NIR\"]                               #Near-infrared band\n",
    "    NIRn  = dict[\"NIRn\"]                              #Near-infrared band\n",
    "    WV    = dict[\"WV\"]                                #Water vapour\n",
    "    SWIR1 = dict[\"SWIR1\"]                             #Short wave infrared 1\n",
    "    SWIR2 = dict[\"SWIR2\"]                             #Short wave infrared 2\n",
    "\n",
    "    bands_for_expressions = {\n",
    "\n",
    "        'blue'  : image.select(blue).divide(10000),\n",
    "        'green' : image.select(green).divide(10000), \n",
    "        'red'   : image.select(red).divide(10000),\n",
    "        'red1'  : image.select(red1).divide(10000), \n",
    "        'red2'  : image.select(red2).divide(10000),\n",
    "        'red3'  : image.select(red3).divide(10000), \n",
    "        'NIR'   : image.select(NIR).divide(10000),\n",
    "        'NIRn'  : image.select(NIRn).divide(10000),\n",
    "        'WV'    : image.select(WV).divide(10000),\n",
    "        'SWIR1' : image.select(SWIR1).divide(10000),\n",
    "        'SWIR2' : image.select(SWIR2).divide(10000)}\n",
    "\n",
    "    # greeness related indices\n",
    "    # NDVI                                                                             (Rouse et al., 1974)\n",
    "    NDVI  = image.normalizedDifference([NIR, red]).rename(\"NDVI\") \n",
    "    # EVI                                                                             \n",
    "    EVI   = image.expression('2.5*(( NIR - red ) / ( NIR + 6 * red - 7.5 * blue + 1 ))', \n",
    "            bands_for_expressions).rename(\"EVI\")\n",
    "    # EVI2                                                                             (Jiang et al., 2008)\n",
    "    EVI2  = image.expression('2.5*(( NIR - red ) / ( NIR + 2.4 * red + 1 ))', \n",
    "            bands_for_expressions).rename(\"EVI2\")\n",
    "\n",
    "    # greeness related indices with Sentinel-2 narrow bands / Red-edge\n",
    "    # Clr\n",
    "    CLr  = image.expression('(red3/red1)-1', bands_for_expressions).rename(\"CLr\")\n",
    "    # Clg\n",
    "    Clg  = image.expression('(red3/green)-1', bands_for_expressions).rename(\"CLg\")\n",
    "    # MTCI\n",
    "    MTCI = image.expression('(red2-red1)/(red1-red)', bands_for_expressions).rename(\"MTCI\")\n",
    "    # MNDVI                                                                            (Add reference)\n",
    "    MNDVI = image.normalizedDifference([red3, red1]).rename(\"MNDVI\")    \n",
    "\n",
    "    # water related indices\n",
    "    # MNDWI                                                                            (Add reference)\n",
    "    MNDWI = image.normalizedDifference([green, SWIR1]).rename(\"MNDWI\")    \n",
    "    # NDWI OR LSWI or NDII or NDMI                                                     (Add reference)\n",
    "    LSWI  = image.normalizedDifference([NIR, SWIR1]).rename(\"LSWI\")\n",
    "    # NDII                                                                             (Hunt & Qu, 2013)\n",
    "    NDII   = image.normalizedDifference([NIR, SWIR2]).rename(\"NDII\")\n",
    "\n",
    "    image = image.addBands(NDVI).addBands(EVI).addBands(EVI2)\n",
    "    image = image.addBands(CLr).addBands(Clg).addBands(MTCI).addBands(MNDVI)\n",
    "    image = image.addBands(MNDWI).addBands(LSWI).addBands(NDII)\n",
    "\n",
    "    return image \n",
    "\n",
    "def vimasking(image):\n",
    "\n",
    "        ndvi  = image.select('NDVI')\n",
    "        mndvi = image.select('MNDVI')\n",
    "\n",
    "        ndviMask = 0\n",
    "        mndviMask = 0\n",
    "\n",
    "        mask = ndvi.gte(ndviMask).And(mndvi.gte(mndviMask))\n",
    "\n",
    "        vegetation = image.updateMask(mask)\n",
    "        return vegetation\n",
    "\n",
    "def cloudmasking(image):\n",
    "\n",
    "        qa    = image.select('QA60')\n",
    "        b2    = image.select('B2')\n",
    "        scl   = image.select('SCL')\n",
    "        ndvi  = image.select('NDVI')\n",
    "        mndvi = image.select('MNDVI')\n",
    "\n",
    "        cloudBitMask = 1 << 10\n",
    "        cirrusBitMask = 1 << 11\n",
    "\n",
    "        #vegetationMask1 = 4 # vegetation\n",
    "        #vegetationMask2 = 5 # non-vegetated\n",
    "        #vegetationMask3 = 6 # water\n",
    "        #vegetationMask4 = 7 # unclassified\n",
    "        #vegetationMask5 = 11 # snow\n",
    "\n",
    "        ndviMask = -100\n",
    "        mndviMask = -100\n",
    "        b2mask = 100\n",
    "\n",
    "        # This mask selects vegetation + non-vegetated + water + unclassified + areas with VIs (NDVI and MNDVI) greater that a threshold set in the configuration file\n",
    "        # mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        # mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(7)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        # mask = scl.eq(4)\n",
    "        # Maps_test_mask_2\n",
    "        # mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(b2.lt(b2mask)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        # Maps_test_mask_3\n",
    "        # mask = scl.neq(6).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        # Maps_test_mask_4\n",
    "        # mask = scl.neq(6).Or(scl.neq(8)).Or(scl.neq(9)).Or(scl.neq(10)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        # Maps_test_mask_4\n",
    "        # mask = scl.neq(6).Or(scl.neq(8)).Or(scl.neq(9)).Or(scl.neq(10)).Or(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        # mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "        vegetation = image.updateMask(mask)\n",
    "        return vegetation\n",
    "\n",
    "def maskS2nonvegetation(image):\n",
    "\n",
    "        qa    = image.select('QA60')\n",
    "        b2    = image.select('B2')\n",
    "        scl   = image.select('SCL')\n",
    "        ndvi  = image.select('NDVI')\n",
    "        mndvi = image.select('MNDVI')\n",
    "\n",
    "        cloudBitMask = 1 << 10\n",
    "        cirrusBitMask = 1 << 11\n",
    "\n",
    "        #vegetationMask1 = 4 # vegetation\n",
    "        #vegetationMask2 = 5 # non-vegetated\n",
    "        #vegetationMask3 = 6 # water\n",
    "        #vegetationMask4 = 7 # unclassified\n",
    "        #vegetationMask5 = 11 # snow\n",
    "\n",
    "        ndviMask = -100\n",
    "        mndviMask = -100\n",
    "        b2mask = 100\n",
    "\n",
    "        # This mask selects vegetation + non-vegetated + water + unclassified + areas with VIs (NDVI and MNDVI) greater that a threshold set in the configuration file\n",
    "        # mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        # mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(7)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        # mask = scl.eq(4)\n",
    "        # Maps_test_mask_2\n",
    "        # mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).And(b2.lt(b2mask)).And(ndvi.gte(ndviMask)).And(mndvi.gte(mndviMask))\n",
    "        # Maps_test_mask_3\n",
    "        # mask = scl.neq(6).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        # Maps_test_mask_4\n",
    "        # mask = scl.neq(6).Or(scl.neq(8)).Or(scl.neq(9)).Or(scl.neq(10)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "        # Maps_test_mask_4\n",
    "        # mask = scl.neq(6).Or(scl.neq(8)).Or(scl.neq(9)).Or(scl.neq(10))\n",
    "        # mask = scl.eq(0).Or(scl.eq(1)).Or(scl.eq(2)).Or(scl.eq(3)).Or(scl.eq(4)).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(8)).Or(scl.eq(9)).Or(scl.eq(10)).Or(scl.eq(11))\n",
    "        # mask = scl.eq(0).Or(scl.eq(1)).Or(scl.eq(2)).Or(scl.eq(3)).Or(scl.eq(4)).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(8)).Or(scl.eq(9)).Or(scl.eq(10)).Or(scl.eq(11))\n",
    "        mask = scl.eq(0).Or(scl.eq(1)).Or(scl.eq(2)).Or(scl.eq(4)).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(11))\n",
    "        vegetation = image.updateMask(mask)\n",
    "        return vegetation\n",
    "\n",
    "def get_s2_array(period,aoi,sentinel_bands, number_img, MGRS_TILE=None,cloud_percentage=100,resolution=100):\n",
    "    ic = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterDate(period[0],period[1])\n",
    "    # ic = ic.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',cloud_percentage))\n",
    "    ic = ic.filterBounds(aoi) \n",
    "    if not MGRS_TILE   is None:\n",
    "        print(f'Retriving collection for {MGRS_TILE} tile')\n",
    "        ic = ic.filter(ee.Filter.eq('MGRS_TILE', MGRS_TILE)) \n",
    "    ic = ic.map(apply_scale_factors_s2)\n",
    "    ic = ic.map(calculateVI)\n",
    "    ic = ic.map(maskS2nonvegetation)\n",
    "    # ic = ic.map(vimasking)\n",
    "    ic = ic.map(cloudmasking)\n",
    "    ic = ic.select(sentinel_bands)\n",
    "\n",
    "    count = ic.size().getInfo()\n",
    "    print('Number of images:', count)\n",
    "    image_names = ic.aggregate_array('system:id').getInfo()\n",
    "    print('Image names:', image_names)\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No images found in the period.\")\n",
    "\n",
    "    if count > 1:\n",
    "        print(\"More than one image in the period.\")\n",
    "        \n",
    "        print('Selecting the first image in the collection:', image_names[number_img])\n",
    "\n",
    "        ic = ic.filter(ee.Filter.eq('system:id', image_names[number_img]))\n",
    "        count = ic.size().getInfo()\n",
    "        print('Number of images:', count)\n",
    "        image_names = ic.aggregate_array('system:id').getInfo()\n",
    "        print('Image names:', image_names)\n",
    "\n",
    "    # ic = ee.ImageCollection(ic.mean())\n",
    "    arrays_list = []\n",
    "    for band in sentinel_bands:\n",
    "        ic_sample = ic.select(band).getRegion(aoi, resolution).getInfo()\n",
    "        arrays_list.append(ic_sample)\n",
    "    \n",
    "    return arrays_list, ic\n",
    "\n",
    "def get_s2_array_nomasked(period,aoi,sentinel_bands, number_img, MGRS_TILE=None,cloud_percentage=100,resolution=100):\n",
    "    ic = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterDate(period[0],period[1])\n",
    "    # ic = ic.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',cloud_percentage))\n",
    "    ic = ic.filterBounds(aoi) \n",
    "    if not MGRS_TILE   is None:\n",
    "        print(f'Retriving collection for {MGRS_TILE} tile')\n",
    "        ic = ic.filter(ee.Filter.eq('MGRS_TILE', MGRS_TILE)) \n",
    "    ic = ic.map(apply_scale_factors_s2)\n",
    "    ic = ic.map(calculateVI)\n",
    "    # ic = ic.map(maskS2nonvegetation)\n",
    "    ic = ic.select(sentinel_bands)\n",
    "\n",
    "    count = ic.size().getInfo()\n",
    "    print('Number of images:', count)\n",
    "    image_names = ic.aggregate_array('system:id').getInfo()\n",
    "    print('Image names:', image_names)\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No images found in the period.\")\n",
    "\n",
    "    if count > 1:\n",
    "        print(\"More than one image in the period.\")\n",
    "        \n",
    "        print('Selecting the first image in the collection:', image_names[number_img])\n",
    "\n",
    "        ic = ic.filter(ee.Filter.eq('system:id', image_names[number_img]))\n",
    "        count = ic.size().getInfo()\n",
    "        print('Number of images:', count)\n",
    "        image_names = ic.aggregate_array('system:id').getInfo()\n",
    "        print('Image names:', image_names)\n",
    "\n",
    "    # ic = ee.ImageCollection(ic.mean())\n",
    "    arrays_list = []\n",
    "    for band in sentinel_bands:\n",
    "        ic_sample = ic.select(band).getRegion(aoi, resolution).getInfo()\n",
    "        arrays_list.append(ic_sample)\n",
    "    \n",
    "    return arrays_list, ic\n",
    "\n",
    "def get_s2_df(s2_array_list):\n",
    "    df_list = []\n",
    "    for s2_array in s2_array_list:\n",
    "        df = pd.DataFrame(s2_array[1:], columns=s2_array[0])\n",
    "        df = df.iloc[:,1:]\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms').dt.date\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df.set_index(['time','latitude','longitude'], inplace=True)\n",
    "        df_list.append(df)\n",
    "    df_final = df_list[0]\n",
    "    df_list.pop(0)\n",
    "    for df in df_list:\n",
    "        df_final = df_final.merge(df, left_index=True, right_index=True, how='left')\n",
    "    return df_final\n",
    "\n",
    "def get_e5_array(period,aoi,e5_bands,resolution=100):\n",
    "    e5 = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR').filterDate(period[0],period[1])\n",
    "    e5 = e5.filterBounds(aoi).select(e5_bands)\n",
    "    e5 = e5.map(apply_scale_factors_e5)\n",
    "    e5_sample = e5.getRegion(aoi, resolution).getInfo()\n",
    "    return e5_sample, e5\n",
    "\n",
    "def get_e5_df(e5_array):\n",
    "    dfe5 = pd.DataFrame(e5_array[1:], columns=e5_array[0])\n",
    "    dfe5['time'] = pd.to_datetime(dfe5['id'], format='%Y%m%d')\n",
    "    dfe5 = dfe5.iloc[:,1:]\n",
    "    dfe5.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    dfe5.rename(columns={'surface_net_solar_radiation_sum':'SW_IN_ERA_GEE'}, inplace=True)\n",
    "    return dfe5\n",
    "\n",
    "def merge_s2_e5(s2_df, e5_df):\n",
    "    df1 = s2_df.reset_index()\n",
    "    df2 = e5_df.reset_index()\n",
    "    df_merged = df1.merge(df2, on=['time', 'lat', 'longitude'], how='left')\n",
    "\n",
    "    df_merged = df_merged.dropna()\n",
    "    df_merged.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df_merged\n",
    "\n",
    "def map_image(ic, aoi, band, label):\n",
    "    # Define visualization parameters\n",
    "    vis_params = {\n",
    "        'min': 0.5,\n",
    "        'max': 1.0,\n",
    "        'palette': ['red', 'white', 'green']\n",
    "    }\n",
    "\n",
    "    # Create a map\n",
    "    Map = geemap.Map()\n",
    "\n",
    "    # Center the map on the area of interest\n",
    "    Map.centerObject(aoi, 12)\n",
    "\n",
    "    # Add the mean NDVI layer to the map\n",
    "    Map.addLayer(ic.select(band), vis_params, label)\n",
    "\n",
    "    # Display the map\n",
    "    return Map\n",
    "\n",
    "def get_environmental_data(directory_data, filename,sentinel_vi,sentinel_bands, general):\n",
    "    env_df = pd.read_csv(os.path.join(directory_data, filename), index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "\n",
    "    s2_all = env_df.columns.values.tolist()\n",
    "    s2_all = sorted([item for item in s2_all if not (item.endswith('_residual') or \n",
    "                                                    item.endswith('_trend') or \n",
    "                                                    item.endswith('_season'))])\n",
    "\n",
    "    s2_all = sorted([item for item in s2_all if not (item.startswith('CO2') or \n",
    "                                                    item.startswith('H_') or \n",
    "                                                    item.startswith('LE_'))])\n",
    "\n",
    "    s2_all = [item for item in s2_all if item not in sentinel_vi]\n",
    "    s2_all = [item for item in s2_all if item not in sentinel_bands]\n",
    "    #s2_all = [item for item in s2_all if item not in general]\n",
    "\n",
    "    selected_columns = s2_all \n",
    "    env_df = env_df[selected_columns]\n",
    "\n",
    "    return env_df\n",
    "\n",
    "def merge_s2_env_data(s2_df, env_df, expected_columns):\n",
    "    s2_df = s2_df.reset_index()\n",
    "    env_df = env_df.reset_index()\n",
    "    env_df = env_df.rename(columns={'TIMESTAMP':'time'})\n",
    "\n",
    "    df_merged = s2_df.merge(env_df, on=['time'], how='left')\n",
    "    df_merged.set_index(['time','latitude','longitude'], inplace=True)\n",
    "\n",
    "    df_merged = df_merged[expected_columns]\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def predict_gpp(df_merged, model_file):\n",
    "    print('Predicting Gross Primary Production')\n",
    "    loaded_model = XGBRegressor()\n",
    "    loaded_model.load_model(model_file)\n",
    "    y_pred = loaded_model.predict(df_merged)\n",
    "    df_merged['GPP'] = y_pred\n",
    "    df_merged = df_merged[df_merged['GPP'] >= 0]\n",
    "    ds_gpp = df_merged.to_xarray()\n",
    "    return ds_gpp, df_merged\n",
    "\n",
    "def plot_save_var(ds, var, netcdf_output, geotif_output):\n",
    "    ds[var].isel(time=0).plot()\n",
    "    crs = CRS.from_epsg(4326) #3857\n",
    "\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "    ds[var].to_netcdf(netcdf_output)\n",
    "\n",
    "    da = ds[var].isel(time=0)\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "    da.rio.to_raster(geotif_output)\n",
    "\n",
    "def sites_info(site_list, directory_data):\n",
    "    df_sites = pd.read_excel(site_list)\n",
    "    df_sites = df_sites.dropna(subset=['deims'])\n",
    "    site_name_list = sorted(df_sites['sites_ids'].values.tolist())\n",
    "    files_list = os.listdir(directory_data)\n",
    "    files_list = sorted([file for file in files_list if any(file.startswith(site_name) for site_name in site_name_list)])\n",
    "\n",
    "    return site_name_list, files_list, df_sites\n",
    "\n",
    "def sites_info_csv(site_list, directory_data):\n",
    "    df_sites = pd.read_csv(site_list, sep=';')\n",
    "    df_sites = df_sites.dropna(subset=['deims'])\n",
    "    site_name_list = sorted(df_sites['sites_ids'].values.tolist())\n",
    "    files_list = os.listdir(directory_data)\n",
    "    files_list = sorted([file for file in files_list if any(file.startswith(site_name) for site_name in site_name_list)])\n",
    "\n",
    "    return site_name_list, files_list, df_sites\n",
    "\n",
    "def plot_save_gpp(ds, site, period, directory_maps): \n",
    "    directory_maps = os.path.join(directory_maps, site)\n",
    "    os.makedirs(directory_maps, exist_ok=True)\n",
    "\n",
    "    print('Saving Gross Primary Production products\\n')   \n",
    "    crs = CRS.from_epsg(4326)\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "\n",
    "    #ds['GPP'].to_netcdf(os.path.join(directory_maps, f'{site} - Gross Primary Production ({period[0]}.nc'))\n",
    "    ds['GPP'].to_netcdf(os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.nc'))\n",
    "\n",
    "    da = ds['GPP'].isel(time=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    da.plot()\n",
    "    plt.title(f'{site} - Gross Primary Production (GPP) - {period[0]}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    da.rio.to_raster(\n",
    "        os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.tif'),\n",
    "        driver='COG',\n",
    "        compress='deflate',\n",
    "        nodata=da.attrs.get('_FillValue', None),\n",
    "        dtype=da.dtype.name\n",
    "    )\n",
    "\n",
    "def plot_save_gpp_all_data(ds, site, period, directory_maps): \n",
    "    directory_maps = os.path.join(directory_maps, site)\n",
    "    os.makedirs(directory_maps, exist_ok=True)\n",
    "\n",
    "    print('Saving Gross Primary Production products\\n')   \n",
    "    crs = CRS.from_epsg(4326)\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "\n",
    "    #ds['GPP'].to_netcdf(os.path.join(directory_maps, f'{site} - Gross Primary Production ({period[0]}.nc'))\n",
    "    ds.to_netcdf(os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.nc'))\n",
    "\n",
    "    da = ds['GPP'].isel(time=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cmap = plt.get_cmap('RdYlGn') \n",
    "    da.plot(cmap=cmap, vmin=0, vmax=15)\n",
    "    plt.title(f'{site} - Gross Primary Production (GPP) - {period[0]}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.png'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    da.rio.to_raster(\n",
    "        os.path.join(directory_maps, f'{site.lower()}_gpp_{period[0].replace(\"-\", \"\")}.tif'),\n",
    "        driver='COG',\n",
    "        compress='deflate',\n",
    "        nodata=da.attrs.get('_FillValue', None),\n",
    "        dtype=da.dtype.name\n",
    "    )\n",
    "\n",
    "    # da = ds['SCL'].isel(time=0)\n",
    "\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # da.plot()\n",
    "    # plt.title(f'{site} - SCL - {period[0]}')\n",
    "    # plt.savefig(os.path.join(directory_maps, f'{site.lower()}_scl_{period[0].replace(\"-\", \"\")}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    da = ds['SCL'].isel(time=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cmap = plt.get_cmap('Spectral') \n",
    "    da.plot(cmap=cmap, vmin=0, vmax=11)\n",
    "\n",
    "    plt.title(f'{site} - SCL - {period[0]}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site.lower()}_scl_{period[0].replace(\"-\", \"\")}.png'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def get_collection_without_clouds(\n",
    "        collection,\n",
    "        year_list,\n",
    "        aoi, \n",
    "        longitude,\n",
    "        latitude,\n",
    "        max_cloud_coverage,\n",
    "        local_cloud_coverage,\n",
    "):\n",
    "    \n",
    "    # function to load data set with specified period and location\n",
    "    def load_catalog(catalog, time, location, bands):\n",
    "        dataset = ee.ImageCollection(catalog).filterDate(time[0],time[1]).filterBounds(location).select(bands)\n",
    "        return dataset\n",
    "\n",
    "    # function to derive VIs\n",
    "    def calculateVI(image):\n",
    "        '''This method calculates different vegetation indices in a image collection and adds their values as new bands'''\n",
    "\n",
    "        # defining dictionary of bands Sentinel-2 \n",
    "        dict_bands = {\n",
    "\n",
    "            \"blue\"  :  'B2',                              #Blue band                        \n",
    "            \"green\" :  'B3',                              #Green band\n",
    "            \"red\"   :  'B4',                              #Red band\n",
    "            \"red1\"  :  'B5',                              #Red-edge spectral band   \n",
    "            \"red2\"  :  'B6',                              #Red-edge spectral band\n",
    "            \"red3\"  :  'B7',                              #Red-edge spectral band    \n",
    "            \"NIR\"   :  'B8',                              #Near-infrared band\n",
    "            \"NIRn\"  :  'B8A',                             #Near-infrared narrow\n",
    "            \"WV\"    :  'B9',                              #Water vapour\n",
    "            \"SWIR1\" :  'B11',                             #Short wave infrared 1\n",
    "            \"SWIR2\" :  'B12',                             #Short wave infrared 2\n",
    "        }\n",
    "\n",
    "        # specify bands \n",
    "        dict  = dict_bands\n",
    "        blue  = dict[\"blue\"]                              #Blue band                        \n",
    "        green = dict[\"green\"]                             #Green band\n",
    "        red   = dict[\"red\"]                               #Red band\n",
    "        red1  = dict[\"red1\"]                              #Red-edge spectral band    \n",
    "        red2  = dict[\"red2\"]                              #Red-edge spectral band\n",
    "        red3  = dict[\"red3\"]                              #Red-edge spectral band\n",
    "        NIR   = dict[\"NIR\"]                               #Near-infrared band\n",
    "        NIRn  = dict[\"NIRn\"]                              #Near-infrared band\n",
    "        WV    = dict[\"WV\"]                                #Water vapour\n",
    "        SWIR1 = dict[\"SWIR1\"]                             #Short wave infrared 1\n",
    "        SWIR2 = dict[\"SWIR2\"]                             #Short wave infrared 2\n",
    "\n",
    "        bands_for_expressions = {\n",
    "\n",
    "            'blue'  : image.select(blue).divide(10000),\n",
    "            'green' : image.select(green).divide(10000), \n",
    "            'red'   : image.select(red).divide(10000),\n",
    "            'red1'  : image.select(red1).divide(10000), \n",
    "            'red2'  : image.select(red2).divide(10000),\n",
    "            'red3'  : image.select(red3).divide(10000), \n",
    "            'NIR'   : image.select(NIR).divide(10000),\n",
    "            'NIRn'  : image.select(NIRn).divide(10000),\n",
    "            'WV'    : image.select(WV).divide(10000),\n",
    "            'SWIR1' : image.select(SWIR1).divide(10000),\n",
    "            'SWIR2' : image.select(SWIR2).divide(10000)}\n",
    "\n",
    "        # greeness related indices\n",
    "        # NDVI                                                                             (Rouse et al., 1974)\n",
    "        NDVI  = image.normalizedDifference([NIR, red]).rename(\"NDVI\") \n",
    "        # EVI                                                                             \n",
    "        EVI   = image.expression('2.5*(( NIR - red ) / ( NIR + 6 * red - 7.5 * blue + 1 ))', \n",
    "                bands_for_expressions).rename(\"EVI\")\n",
    "        # EVI2                                                                             (Jiang et al., 2008)\n",
    "        EVI2  = image.expression('2.5*(( NIR - red ) / ( NIR + 2.4 * red + 1 ))', \n",
    "                bands_for_expressions).rename(\"EVI2\")\n",
    "\n",
    "        # greeness related indices with Sentinel-2 narrow bands / Red-edge\n",
    "        # Clr\n",
    "        CLr  = image.expression('(red3/red1)-1', bands_for_expressions).rename(\"CLr\")\n",
    "        # Clg\n",
    "        Clg  = image.expression('(red3/green)-1', bands_for_expressions).rename(\"CLg\")\n",
    "        # MTCI\n",
    "        MTCI = image.expression('(red2-red1)/(red1-red)', bands_for_expressions).rename(\"MTCI\")\n",
    "        # MNDVI                                                                            (Add reference)\n",
    "        MNDVI = image.normalizedDifference([red3, red1]).rename(\"MNDVI\")    \n",
    "\n",
    "        # water related indices\n",
    "        # MNDWI                                                                            (Add reference)\n",
    "        MNDWI = image.normalizedDifference([green, SWIR1]).rename(\"MNDWI\")    \n",
    "        # NDWI OR LSWI or NDII or NDMI                                                     (Add reference)\n",
    "        LSWI  = image.normalizedDifference([NIR, SWIR1]).rename(\"LSWI\")\n",
    "        # NDII                                                                             (Hunt & Qu, 2013)\n",
    "        NDII   = image.normalizedDifference([NIR, SWIR2]).rename(\"NDII\")\n",
    "\n",
    "        image = image.addBands(NDVI).addBands(EVI).addBands(EVI2)\n",
    "        image = image.addBands(CLr).addBands(Clg).addBands(MTCI).addBands(MNDVI)\n",
    "        image = image.addBands(MNDWI).addBands(LSWI).addBands(NDII)\n",
    "\n",
    "        return image  \n",
    "\n",
    "    # cloud coverage filter function\n",
    "    def cloud_filter(collection, cloud_coverage_metadata_name, threshold):\n",
    "        collection_cf = collection.filterMetadata(cloud_coverage_metadata_name,'less_than', threshold)\n",
    "        # Show messages\n",
    "        print('The maximun cloud coverage in the image is:', max_cloud_coverage)\n",
    "        print('The original size of the collection is', collection.size().getInfo())\n",
    "        # print(s2.first().getInfo())\n",
    "        print('The filtered size of the collection is', collection_cf.size().getInfo(),'\\n')\n",
    "        return collection_cf\n",
    "    \n",
    "    def local_cloud_filter(s2, aoi, LOCAL_CLOUD_THRESH):\n",
    "        # Describe functions\n",
    "        # Function to scale the reflectance bands\n",
    "        def apply_scale_factors_s2(image):\n",
    "            optical_bands = image.select(['B.']).divide(10000)\n",
    "            thermal_bands = image.select(['B.*']).divide(10000)\n",
    "            return image.addBands(optical_bands, None, True).addBands(thermal_bands, None, True)\n",
    "\n",
    "        # Function to create mask with cirrus clouds and cirrus pixels\n",
    "        def extract_bit_s2_10_11(image):\n",
    "            bit_position_clouds = 10\n",
    "            bit_position_cirrus = 11\n",
    "\n",
    "            # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "            cloud_bit_mask = 1 << bit_position_clouds\n",
    "            cirrus_bit_mask = 1 << bit_position_cirrus\n",
    "\n",
    "            mask_clouds = image.bitwiseAnd(cloud_bit_mask).rightShift(bit_position_clouds)\n",
    "            mask_cirrus = image.bitwiseAnd(cirrus_bit_mask).rightShift(bit_position_cirrus)\n",
    "            mask = mask_clouds.add(mask_cirrus)\n",
    "            return mask\n",
    "\n",
    "        # Function to mask pixels with high reflectance in the blue (B2) band. The function creates a QA band\n",
    "        def b2_mask(image):\n",
    "            B2Threshold = 0.2\n",
    "            B2Mask = image.select('B2').gt(B2Threshold)\n",
    "            return image.addBands(B2Mask.rename('B2Mask'))\n",
    "\n",
    "        # Function to create a band with ones\n",
    "        def make_ones(image):\n",
    "            # Create a band with ones\n",
    "            ones_band = image.select('B2').divide(image.select('B2'))\n",
    "            return image.addBands(ones_band.rename('Ones'))\n",
    "\n",
    "        # Function to calculate area\n",
    "        def get_area(img):\n",
    "            cloud_area = make_ones(img).select('Ones').multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=30).values().get(0)\n",
    "            return img.set('area_image', ee.Number(cloud_area))\n",
    "\n",
    "        # Function to get local cloud percentage with QA band\n",
    "        def get_local_cloud_percentage(img):\n",
    "            error_margin = 1 # meter\n",
    "            cloud_area = extract_bit_s2_10_11(img.select('QA60')).multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage', ee.Number(cloud_area).divide(aoi.area(maxError=error_margin)).multiply(100).round())\n",
    "\n",
    "        # Function to get local cloud percentage with QA and area of image band\n",
    "        def get_local_cloud_percentage_area_image(img):\n",
    "            area_image = img.get('area_image')\n",
    "            cloud_area = extract_bit_s2_10_11(img.select('QA60')).multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage_ai', ee.Number(cloud_area).divide(ee.Number(area_image)).multiply(100).round())\n",
    "\n",
    "        # Function to get local cloud percentage with B2 and area of image band\n",
    "        def get_local_cloud_percentage_area_image_b2(img):\n",
    "            area_image = img.get('area_image')\n",
    "            cloud_area = b2_mask(img).select('B2Mask').multiply(ee.Image.pixelArea()) \\\n",
    "                .reduceRegion(reducer=ee.Reducer.sum(), geometry=aoi, scale=60).values().get(0)\n",
    "            return img.set('local_cloud_percentage_ai_b2', ee.Number(cloud_area).divide(ee.Number(area_image)).multiply(100).round())\n",
    "\n",
    "        # def add_ndvi(image):\n",
    "        #     # Calculate NDVI\n",
    "        #     ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        #     return image.addBands(ndvi)\n",
    "\n",
    "        s2 = s2.filterBounds(aoi).map(lambda image: image.clip(aoi)).map(apply_scale_factors_s2) #.map(add_ndvi)\n",
    "        \n",
    "        # Processing\n",
    "        # Calculate area\n",
    "        s2 = s2.map(get_area)\n",
    "        # Calculate local cloud percentage with QA band\n",
    "        s2 = s2.map(get_local_cloud_percentage)\n",
    "        # Calculate local cloud percentage with QA band and area image band\n",
    "        s2 = s2.map(get_local_cloud_percentage_area_image)\n",
    "        # Calculate local cloud percentage with B2 band and area image band\n",
    "        s2 = s2.map(get_local_cloud_percentage_area_image_b2)\n",
    "        # Filter images\n",
    "        s2_filtered = s2.filter(ee.Filter.lte('local_cloud_percentage_ai', LOCAL_CLOUD_THRESH))\n",
    "        s2_filtered = s2_filtered.filter(ee.Filter.lte('local_cloud_percentage_ai_b2', LOCAL_CLOUD_THRESH))\n",
    "\n",
    "        # Show messages\n",
    "        print('The maximun cloud coverage in the area is:', LOCAL_CLOUD_THRESH)\n",
    "        print('The original size of the collection is', s2.size().getInfo())\n",
    "        # print(s2.first().getInfo())\n",
    "        print('The filtered size of the collection is', s2_filtered.size().getInfo(),'\\n')\n",
    "        \n",
    "        return s2_filtered \n",
    "\n",
    "    # function for masking non-vegetation areas\n",
    "    def maskS2nonvegetation(image):\n",
    "\n",
    "            qa    = image.select('QA60')\n",
    "            scl   = image.select('SCL')\n",
    "            ndvi  = image.select('NDVI')\n",
    "            mndvi = image.select('MNDVI')\n",
    "\n",
    "            cloudBitMask = 1 << 10\n",
    "            cirrusBitMask = 1 << 11\n",
    "\n",
    "            #vegetationMask1 = 4 # vegetation\n",
    "            #vegetationMask2 = 5 # non-vegetated\n",
    "            #vegetationMask3 = 6 # water\n",
    "            #vegetationMask4 = 7 # unclassified\n",
    "            #vegetationMask5 = 11 # snow\n",
    "\n",
    "            # this mask selects vegetation + non-vegetated + water + unclassified + areas with VIs (NDVI and MNDVI) greater that a threshold set in the configuration file\n",
    "            mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7)).Or(scl.eq(11)).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "            # mask = scl.eq(4).And(qa.bitwiseAnd(cloudBitMask).eq(0)).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "            # mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "            vegetation = image.updateMask(mask)\n",
    "\n",
    "            return vegetation\n",
    "    \n",
    "    # get inpu data\n",
    "    # create a only file per year identified in the input files\n",
    "    years = year_list\n",
    "\n",
    "    # create range according to data in the input datafiles   \n",
    "    start   = '%s-01-01'   %(years[0])                                                                                          \n",
    "    end     = '%s-12-31'   %(years[-1])                                            \n",
    "    timeSD  = [start, end]\n",
    "\n",
    "    # create coordinates of the eddy covariance tower\n",
    "    lon_lat =  [longitude, latitude]         \n",
    "    point   = ee.Geometry.Point(lon_lat)\n",
    "\n",
    "    # collections google earth engine    \n",
    "    COPERNICUS_S2_L2A = collection #Multi-spectral surface reflectances (https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR)       \n",
    "    COPERNICUS_S2_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'AOT', 'WVP', 'SCL', 'TCI_R', 'TCI_G', 'TCI_B', 'QA10', 'QA20', 'QA60']\n",
    "\n",
    "    # applying functions \n",
    "    # request of catalogues \n",
    "    S2_VI     = load_catalog(COPERNICUS_S2_L2A, timeSD, point, COPERNICUS_S2_bands)\n",
    "\n",
    "    # filter cloud coverage\n",
    "    cloud_coverage_metadata_name = 'CLOUDY_PIXEL_PERCENTAGE'                     # name of metadata property indicating cloud coverage in %\n",
    "\n",
    "    # applying cloud filter \n",
    "    S2_VI = cloud_filter(S2_VI, cloud_coverage_metadata_name, max_cloud_coverage)   # max cloud coverage defined in the Config file\n",
    "\n",
    "    # apply cloud local filter\n",
    "    S2_VI = local_cloud_filter(S2_VI, aoi, local_cloud_coverage)\n",
    "\n",
    "    # calculation of vegetation indices for the collection\n",
    "    S2_VI = S2_VI.map(calculateVI)\n",
    "\n",
    "    # applying mask \n",
    "    S2_VI = S2_VI.map(maskS2nonvegetation)\n",
    "\n",
    "    return S2_VI, point\n",
    "\n",
    "def get_ecosystem_geometry(training_dataset,number_clusters,training_scale,scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent):\n",
    "    #https://code.earthengine.google.com/2b95fd6462c6c906d4ed9a74fae51bf4\n",
    "    Region    =  point.buffer(ecosystem_extent/2)\n",
    "    inputML   =  ic.select(bands).median().clip(Region)\n",
    "\n",
    "    # This trainning function takes pixes or pixels even in larger region than inputML\n",
    "    training  = inputML.sample(region=Region, scale=training_scale, numPixels=training_dataset)\n",
    "    clusterer = ee.Clusterer.wekaKMeans(number_clusters).train(training)\n",
    "\n",
    "    result    = inputML.cluster(clusterer)\n",
    "    results_colect  = ee.ImageCollection([result])\n",
    "    df_clus = results_colect.getRegion(point, scale_getRegion).getInfo()\n",
    "    df_clus = pd.DataFrame(df_clus)\n",
    "    headers = df_clus.iloc[0]\n",
    "    df_clus = pd.DataFrame(df_clus.values[1:], columns=headers).set_index('id')\n",
    "    cluster_ecosystem = df_clus['cluster'][0]\n",
    "    results_shp = result.reduceToVectors(scale=vector_scale, bestEffort=True)\n",
    "\n",
    "    def classification(weka, num):\n",
    "        class_vegetation = weka.select('label').filter(ee.Filter.eq('label', num))\n",
    "        return class_vegetation\n",
    "\n",
    "    cluster_name = []\n",
    "    for i in range(number_clusters):\n",
    "        globals()['cluster_%s'%i] = classification(results_shp, i).union(1).geometry()\n",
    "        cluster_name.append(globals()['cluster_%s'%i])\n",
    "\n",
    "    cluster_ecosystem_geometry  = cluster_name[cluster_ecosystem]\n",
    "\n",
    "    et_image = ee.ImageCollection([result.eq(cluster_ecosystem)])\n",
    "\n",
    "    return inputML, et_image, cluster_ecosystem_geometry \n",
    "\n",
    "def get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year, point, fetch_70):\n",
    "    # define a method for displaying Earth Engine image tiles on a folium map.\n",
    "    def add_ee_layer(self, ee_object, vis_params, name):\n",
    "        try:    \n",
    "\n",
    "            # display ee.Image()\n",
    "            if isinstance(ee_object, ee.image.Image):    \n",
    "                map_id_dict = ee.Image(ee_object).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "                ).add_to(self)\n",
    "\n",
    "            # display ee.ImageCollection()\n",
    "            elif isinstance(ee_object, ee.imagecollection.ImageCollection):    \n",
    "                ee_object_new = ee_object.mosaic()\n",
    "                map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "                ).add_to(self)\n",
    "\n",
    "            # display ee.Geometry()\n",
    "            elif isinstance(ee_object, ee.geometry.Geometry):    \n",
    "                folium.GeoJson(\n",
    "                data = ee_object.getInfo(),\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True,\n",
    "                style_function=lambda x:vis_params\n",
    "            ).add_to(self)\n",
    "\n",
    "            # display ee.FeatureCollection()\n",
    "            elif isinstance(ee_object, ee.featurecollection.FeatureCollection):  \n",
    "                ee_object_new = ee.Image().paint(ee_object, 0, 2)\n",
    "                map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n",
    "                folium.raster_layers.TileLayer(\n",
    "                tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                attr = 'Google Earth Engine',\n",
    "                name = name,\n",
    "                overlay = True,\n",
    "                control = True\n",
    "            ).add_to(self)\n",
    "\n",
    "        except:\n",
    "            print(\"Could not display {}\".format(name))\n",
    "\n",
    "    # add EE drawing method to folium.\n",
    "    folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "    # Add custom basemaps to folium\n",
    "    basemaps = {\n",
    "        'Google Maps': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Maps',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Satellite': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Terrain': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=p&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Terrain',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Google Satellite Hybrid': folium.TileLayer(\n",
    "            tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n",
    "            attr = 'Google',\n",
    "            name = 'Google Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        ),\n",
    "        'Esri Satellite': folium.TileLayer(\n",
    "            tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "            attr = 'Esri',\n",
    "            name = 'Esri Satellite',\n",
    "            overlay = True,\n",
    "            control = True\n",
    "        )\n",
    "    }\n",
    "\n",
    "    directory_maps = os.path.join(directory_maps, site)\n",
    "    os.makedirs(directory_maps, exist_ok=True) \n",
    "\n",
    "    # Mapping with folium\n",
    "    # a) create a folium map object.\n",
    "    my_map = folium.Map(location= [latitude,longitude], zoom_start=12)\n",
    "    # b) add custom basemaps\n",
    "    basemaps['Esri Satellite'].add_to(my_map)\n",
    "    basemaps['Google Satellite Hybrid'].add_to(my_map)\n",
    "    # c) set visualization parameters.\n",
    "    vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 4000,\n",
    "    'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}\n",
    "    # d) display Geometry\n",
    "    vis_params_geometry = dict(color='red', weight=2, opacity=10, fillColor='red')\n",
    "    my_map.add_ee_layer(cluster_ecosystem_geometry,  vis_params_geometry , 'Ecosystem area')\n",
    "    vis_params_geometry = dict(color='blue', weight=2, opacity=10, fillColor='red')\n",
    "    my_map.add_ee_layer(point,  vis_params_geometry , 'Eddy covariance tower')\n",
    "    my_map.add_ee_layer(point.buffer(fetch_70),  vis_params_geometry , 'Eddy covariance fetch')\n",
    "    # d) display ee.Image\n",
    "    dataset        = inputML.select('NDVI')\n",
    "    vis_params = {\n",
    "        'min': 0.5,\n",
    "        'max': 1.0,\n",
    "        'palette': ['red', 'white', 'green']\n",
    "    }\n",
    "    my_map.add_ee_layer(dataset, vis_params, 'NDVI')\n",
    "    # e) add a layer control panel to the map.\n",
    "    my_map.add_child(folium.LayerControl())\n",
    "    plugins.Fullscreen().add_to(my_map)\n",
    "    \n",
    "    my_map.save(os.path.join(directory_maps, f'{site} - Ecosystem map ({year}).html'))\n",
    "    return my_map\n",
    "\n",
    "def get_et_df(et_array, year):\n",
    "    df = pd.DataFrame(et_array[1:], columns=et_array[0])\n",
    "    df = df.iloc[:,1:]\n",
    "    df['time'] =  pd.to_datetime(f'{year}')\n",
    "    df.set_index(['time','latitude','longitude'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def plot_save_et(image, aoi, site, year, directory_maps, mse, test_r2, mae, rmse): \n",
    "    print(f'Saving Uncertainty product for {year}\\n')  \n",
    "\n",
    "    directory_maps = os.path.join(directory_maps, site)\n",
    "    os.makedirs(directory_maps, exist_ok=True) \n",
    "\n",
    "    et_sample = image.getRegion(aoi, 10).getInfo()\n",
    "    df_et =  get_et_df(et_sample, year)\n",
    "    ds = df_et.to_xarray()\n",
    "\n",
    "    crs = CRS.from_epsg(4326)\n",
    "    ds.attrs['crs'] = crs.to_string()\n",
    "    ds.attrs['title'] = f'Gross Primary Production Uncertainty Map - {year}'\n",
    "    ds.attrs['description'] = 'This COG file represents the uncertainty in Gross Primary Production estimates for the specified year.'\n",
    "    ds.attrs['source'] = site\n",
    "    ds.attrs['year'] = year\n",
    "    ds.attrs['MSE'] = mse\n",
    "    ds.attrs['MAE'] = mae\n",
    "    ds.attrs['RMSE'] = rmse\n",
    "    ds.attrs['R^2'] = test_r2\n",
    "\n",
    "    ds['cluster'].to_netcdf(os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.nc'))\n",
    "\n",
    "    # da = ds['cluster'].isel(time=0)\n",
    "    # da.attrs['crs'] = crs.to_string()\n",
    "    # da.attrs['title'] = f'Gross Primary Production Uncertainty Map - {year}'\n",
    "    # da.attrs['description'] = 'This COG file represents the uncertainty in Gross Primary Production estimates for the specified year.'\n",
    "    # da.attrs['source'] = site\n",
    "    # da.attrs['year'] = year\n",
    "    # da.attrs['MSE'] = mse\n",
    "    # da.attrs['MAE'] = mae\n",
    "    # da.attrs['RMSE'] = rmse\n",
    "    # da.attrs['R^2'] = test_r2\n",
    "\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # da.plot()\n",
    "    # plt.title(f'{site} - Gross Primary Production (GPP) - Uncertainty Map - {year}')\n",
    "    # plt.savefig(os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.png'))\n",
    "    # plt.close()\n",
    "\n",
    "    # da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    # da.rio.to_raster(\n",
    "    #     os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.tif'),\n",
    "    #     driver='COG',\n",
    "    #     compress='deflate',\n",
    "    #     nodata=da.attrs.get('_FillValue', None),\n",
    "    #     dtype=da.dtype.name\n",
    "    # )\n",
    "    \n",
    "    da = ds['cluster'].isel(time=0)\n",
    "    da.attrs.update({\n",
    "        'crs': crs.to_string(),\n",
    "        'title': f'Gross Primary Production Uncertainty Map - {year}',\n",
    "        'description': 'This COG file represents the uncertainty in Gross Primary Production estimates for the specified year.',\n",
    "        'source': site,\n",
    "        'year': year,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R^2': test_r2,\n",
    "    })\n",
    "\n",
    "    # Plotting the uncertainty map\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cmap = plt.get_cmap('cividis', 2)\n",
    "    da.plot(cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.title(f'{site} - Gross Primary Production (GPP) - Uncertainty Map - {year}')\n",
    "    plt.savefig(os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.png'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Write CRS and save as a COG TIFF file\n",
    "    da.rio.write_crs(crs.to_string(), inplace=True)\n",
    "\n",
    "    # Ensure the output directory exists for the TIFF file\n",
    "    tiff_path = os.path.join(directory_maps, f'{site.lower()}_gpp_uncertainty_map_{year}.tif')\n",
    "    \n",
    "    da.rio.to_raster(\n",
    "        tiff_path,\n",
    "        driver='COG',\n",
    "        compress='deflate',\n",
    "        nodata=da.attrs.get('_FillValue', None),\n",
    "        dtype='uint8'\n",
    "    )\n",
    "    \n",
    "    print(f'Uncertainty map saved as: {tiff_path}')\n",
    "\n",
    "\n",
    "def get_testing_data(directory_data, filename, expected_columns, gpp_column):\n",
    "    env_df = pd.read_csv(os.path.join(directory_data, filename), index_col='TIMESTAMP', parse_dates=['TIMESTAMP'])\n",
    "    env_testing = env_df[expected_columns]\n",
    "    gpp_testing = env_df[gpp_column]\n",
    "    return env_testing, gpp_testing\n",
    "\n",
    "def predict_gpp_df(df, model_file):\n",
    "    print('Testing Gross Primary Production')\n",
    "    loaded_model = XGBRegressor()\n",
    "    loaded_model.load_model(model_file)\n",
    "    y_pred = loaded_model.predict(df)\n",
    "    df['GPP_predicted'] = y_pred\n",
    "    return df\n",
    "\n",
    "def get_performance(df, year):\n",
    "    df = df.reset_index()\n",
    "    df = df[df['TIMESTAMP'].dt.year == int(year)]\n",
    "    y_test = df['GPP_testing']\n",
    "    y_pred = df['GPP_predicted']\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('Root Mean Squared Error:', rmse)\n",
    "    print('MAE:', mae)\n",
    "    print(\"Test R^2 Score:\", test_r2,'\\n')\n",
    "\n",
    "    return df, mse, test_r2, mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "site_list = r'D:\\Proyectos2024\\Agame\\Output\\sites_selection\\sites_table_filtered_4y.csv'\n",
    "model_file = r\"D:\\Proyectos2024\\Agame\\Output\\model_12_sites_era\\xgboost_model_12_sites_era.json\"\n",
    "directory_data = r'D:\\Proyectos2024\\Agame\\Output\\Tables'\n",
    "directory_maps = r'D:\\Proyectos2024\\Agame\\Output\\Maps_test_mask'\n",
    "\n",
    "expected_columns = ['CLr', 'EVI', 'EVI2', 'LSWI', 'LW_IN_ERA','LW_IN_JSB_ERA', 'MNDVI', 'MNDWI', 'NDII', 'NDVI', 'PA_ERA', 'P_ERA', 'SW_IN_ERA', 'TA_ERA', 'VPD_ERA', 'WS_ERA', 'biom_deciduous broadleaf forests', 'biom_evergreen needleleaf forests', 'biom_grasslands', 'biom_mixed forests', 'canopy_height', 'elevation', 'fall', 'lat', 'lon', 'spring', 'summer', 'winter'] \n",
    "expected_columns = ['CLr', 'EVI', 'EVI2', 'LSWI', 'LW_IN_ERA', 'LW_IN_JSB_ERA', 'MNDVI', 'MNDWI', 'NDII', 'NDVI', 'PA_ERA', 'P_ERA', 'SW_IN_ERA', 'TA_ERA', 'VPD_ERA', 'WS_ERA', 'biom_deciduous broadleaf forests', 'biom_evergreen needleleaf forests', 'biom_grasslands', 'biom_mixed forests', 'canopy_height', 'elevation', 'fall', 'lat', 'lon', 'spring', 'summer', 'winter', 'day', 'month']\n",
    "expected_columns = ['CLr', 'EVI', 'EVI2', 'LSWI', 'LW_IN_ERA', 'LW_IN_JSB_ERA', 'MNDVI', 'MNDWI', 'NDII', 'NDVI', 'PA_ERA', 'P_ERA', 'SW_IN_ERA', 'TA_ERA', 'VPD_ERA', 'WS_ERA', 'biom_deciduous broadleaf forests', 'biom_evergreen needleleaf forests', 'biom_grasslands', 'biom_mixed forests', 'canopy_height', 'day', 'elevation', 'fall', 'lat', 'lon', 'month', 'spring', 'summer', 'winter']\n",
    "date_range_values = ['2021-01-01','2021-12-31'] \n",
    "# date_range_values = ['2021-07-20','2021-07-21'] \n",
    "# date_range_values = ['2021-01-01','2021-01-02'] \n",
    "# date_range_values = ['2021-02-02', '2021-02-03'] \n",
    "\n",
    "# MGRS_TILE = '34VFP' #'35VLJ'\n",
    "MGRS_TILE = None\n",
    "\n",
    "max_cloud_coverage   = 100\n",
    "local_cloud_coverage = 0\n",
    "training_dataset = 10000\n",
    "# number_clusters = 2 # Torgnon = 3\n",
    "training_scale = 10\n",
    "scale_getRegion = 10\n",
    "vector_scale = 10\n",
    "ecosystem_extent = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "general = [\n",
    "'lat', \n",
    "'lon', \n",
    "'elevation', \n",
    "'canopy_height', \n",
    "'biom_evergreen needleleaf forests',\n",
    "'biom_grasslands',\n",
    "'biom_deciduous broadleaf forests',\n",
    "'biom_mixed forests',\n",
    "'winter',\n",
    "'spring', \n",
    "'summer', \n",
    "'fall']\n",
    "\n",
    "era_var = [\n",
    " 'LW_IN_ERA',\n",
    " 'LW_IN_JSB_ERA',\n",
    " 'PA_ERA',\n",
    " 'P_ERA',\n",
    " 'SW_IN_ERA',\n",
    " 'TA_ERA',\n",
    " 'VPD_ERA',\n",
    " 'WS_ERA']\n",
    "\n",
    "bands = [\n",
    " 'B1',\n",
    " 'B2',\n",
    " 'B3',\n",
    " 'B4',\n",
    " 'B5',\n",
    " 'B6',\n",
    " 'B7',\n",
    " 'B8',\n",
    " 'B8A', \n",
    " 'B9',\n",
    " 'B11',\n",
    " 'B12']\n",
    "\n",
    "sentinel = [\n",
    " 'CLr',\n",
    " 'EVI',\n",
    " 'EVI2',\n",
    " 'LSWI', \n",
    " 'MNDVI',\n",
    " 'MNDWI',\n",
    " 'NDII',\n",
    " 'NDVI']\n",
    "\n",
    "sentinel_full = [\n",
    " 'CLr',\n",
    " 'EVI',\n",
    " 'EVI2',\n",
    " 'LSWI', \n",
    " 'MNDVI',\n",
    " 'MNDWI',\n",
    " 'NDII',\n",
    " 'NDVI',\n",
    " 'QA60',\n",
    " 'B2',\n",
    " 'SCL'\n",
    " ]\n",
    "\n",
    "s2_era_general = sentinel.copy()\n",
    "s2_era_general.extend(era_var)\n",
    "s2_era_general.extend(general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['SE-Svb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_name_list, files_list, df_sites = sites_info_csv(site_list, directory_data)\n",
    "site_name_list = site_name_list[17:]\n",
    "files_list = files_list[17:]\n",
    "site_name_list \n",
    "# del files_list[0]\n",
    "# del site_name_list[0]\n",
    "# del files_list[1]\n",
    "# del site_name_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating products for SE-Svb\n",
      "\n",
      "The area of the site is 67340866.87546413 square meters\n",
      "The area of the site is 67.34086687546413 square kilometers\n",
      "\n",
      "The area of the site is higher than 25 square kilometer. A new area with a maximun of 25 square kilometer will be created\n",
      "The new area of the site is 24862074.67305376 square meters\n",
      "The mew area of the site is 24.862074673053762 square kilometers\n",
      "The site geometry is ready to extract Earth Observation data\n",
      "\n",
      "Testing Gross Primary Production\n",
      "Calculating uncerstainty product for SE-Svb in 2021\n",
      "\n",
      "Mean Squared Error: 1.4174467406018547\n",
      "Root Mean Squared Error: 1.1905657229241293\n",
      "MAE: 0.771812716118867\n",
      "Test R^2 Score: 0.8819648246313287 \n",
      "\n",
      "The maximun cloud coverage in the image is: 100\n",
      "The original size of the collection is 179\n",
      "The filtered size of the collection is 178 \n",
      "\n",
      "The maximun cloud coverage in the area is: 0\n",
      "The original size of the collection is 178\n",
      "The filtered size of the collection is 14 \n",
      "\n",
      "Saving Uncertainty product for 2021\n",
      "\n",
      "Uncertainty map saved as: D:\\Proyectos2024\\Agame\\Output\\Maps_test_mask\\SE-Svb\\se-svb_gpp_uncertainty_map_2021.tif\n",
      "Period: 2021-01-01, 2021-01-02\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-02, 2021-01-03\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-03, 2021-01-04\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-04, 2021-01-05\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-05, 2021-01-06\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-06, 2021-01-07\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-07, 2021-01-08\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-08, 2021-01-09\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-09, 2021-01-10\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-10, 2021-01-11\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-11, 2021-01-12\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-12, 2021-01-13\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-13, 2021-01-14\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-14, 2021-01-15\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-15, 2021-01-16\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-16, 2021-01-17\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-17, 2021-01-18\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-18, 2021-01-19\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210118T101249_20210118T101244_T34WDS']\n",
      "This dataset is empty\n",
      "Period: 2021-01-19, 2021-01-20\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-20, 2021-01-21\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-21, 2021-01-22\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210121T102239_20210121T102236_T34WDS']\n",
      "This dataset is empty\n",
      "Period: 2021-01-22, 2021-01-23\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-23, 2021-01-24\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-24, 2021-01-25\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210124T103229_20210124T103227_T34WDS']\n",
      "This dataset is empty\n",
      "Period: 2021-01-25, 2021-01-26\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-26, 2021-01-27\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-27, 2021-01-28\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-28, 2021-01-29\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210128T101159_20210128T101158_T34WDS']\n",
      "This dataset is empty\n",
      "Period: 2021-01-29, 2021-01-30\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-30, 2021-01-31\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-01-31, 2021-02-01\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210131T102149_20210131T102149_T34WDS']\n",
      "This dataset is empty\n",
      "Period: 2021-02-01, 2021-02-02\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-02-02, 2021-02-03\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210202T101231_20210202T101230_T34WDS']\n",
      "Predicting Gross Primary Production\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210202T101231_20210202T101230_T34WDS']\n",
      "The GPP data of interest is below 50 percent of the validated area\n",
      "Period: 2021-02-03, 2021-02-04\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210203T103139_20210203T103135_T34WDS']\n",
      "Predicting Gross Primary Production\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210203T103139_20210203T103135_T34WDS']\n",
      "The GPP data of interest is below 50 percent of the validated area\n",
      "Period: 2021-02-04, 2021-02-05\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "An unexpected error occurred: ImageCollection.getRegion: No bands in collection.\n",
      "Trying with second error in collection\n",
      "Number of images: 0\n",
      "Image names: []\n",
      "No images found in the period.\n",
      "Earth Engine Exception: ImageCollection.getRegion: No bands in collection.\n",
      "\n",
      "Period: 2021-02-05, 2021-02-06\n",
      "Number of images: 1\n",
      "Image names: ['COPERNICUS/S2_SR_HARMONIZED/20210205T102221_20210205T102235_T34WDS']\n",
      "An unexpected error occurred: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Trying with second error in collection\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='earthengine-highvolume.googleapis.com', port=443): Max retries exceeded with url: /v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001DB035C9650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\http\\client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1386\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\http\\client.py:294\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\packages\\six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\http\\client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1386\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\http\\client.py:294\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 46\u001b[0m\n\u001b[0;32m     45\u001b[0m number_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 46\u001b[0m s2_array, s2 \u001b[38;5;241m=\u001b[39m \u001b[43mget_s2_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentinel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMGRS_TILE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMGRS_TILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcloud_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m s2_df \u001b[38;5;241m=\u001b[39m get_s2_df(s2_array)\n",
      "Cell \u001b[1;32mIn[3], line 402\u001b[0m, in \u001b[0;36mget_s2_array\u001b[1;34m(period, aoi, sentinel_bands, number_img, MGRS_TILE, cloud_percentage, resolution)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m band \u001b[38;5;129;01min\u001b[39;00m sentinel_bands:\n\u001b[1;32m--> 402\u001b[0m     ic_sample \u001b[38;5;241m=\u001b[39m \u001b[43mic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mband\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetRegion\u001b[49m\u001b[43m(\u001b[49m\u001b[43maoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m     arrays_list\u001b[38;5;241m.\u001b[39mappend(ic_sample)\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m  The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\data.py:1101\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   1099\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[1;32m-> 1101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\data.py:402\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\_cloud_api_utils.py:65\u001b[0m, in \u001b[0;36m_Http.request\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m redirections  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders)\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:1058\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1058\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001DB035C9650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='earthengine-highvolume.googleapis.com', port=443): Max retries exceeded with url: /v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001DB035C9650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrying with second error in collection\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m number_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 87\u001b[0m s2_array, s2 \u001b[38;5;241m=\u001b[39m \u001b[43mget_s2_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\u001b[43maoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43msentinel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMGRS_TILE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMGRS_TILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcloud_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m s2_df \u001b[38;5;241m=\u001b[39m get_s2_df(s2_array)\n\u001b[0;32m     89\u001b[0m s2_df \u001b[38;5;241m=\u001b[39m s2_df\u001b[38;5;241m.\u001b[39mdropna()\n",
      "Cell \u001b[1;32mIn[3], line 380\u001b[0m, in \u001b[0;36mget_s2_array\u001b[1;34m(period, aoi, sentinel_bands, number_img, MGRS_TILE, cloud_percentage, resolution)\u001b[0m\n\u001b[0;32m    377\u001b[0m ic \u001b[38;5;241m=\u001b[39m ic\u001b[38;5;241m.\u001b[39mmap(cloudmasking)\n\u001b[0;32m    378\u001b[0m ic \u001b[38;5;241m=\u001b[39m ic\u001b[38;5;241m.\u001b[39mselect(sentinel_bands)\n\u001b[1;32m--> 380\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[43mic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of images:\u001b[39m\u001b[38;5;124m'\u001b[39m, count)\n\u001b[0;32m    382\u001b[0m image_names \u001b[38;5;241m=\u001b[39m ic\u001b[38;5;241m.\u001b[39maggregate_array(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem:id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgetInfo()\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\data.py:1101\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   1098\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[0;32m   1099\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[1;32m-> 1101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\data.py:402\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes a Cloud API call and translates errors to EEExceptions.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m  EEException if the call fails.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    404\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[0;32m    236\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\ee\\_cloud_api_utils.py:65\u001b[0m, in \u001b[0;36m_Http.request\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m connection_type  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m redirections  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m     69\u001b[0m headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\Deltares_GPP\\Lib\\site-packages\\requests\\adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='earthengine-highvolume.googleapis.com', port=443): Max retries exceeded with url: /v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001DB035C9650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "for index in range(len(site_name_list)):\n",
    "\n",
    "    print(f'Calculating products for {site_name_list[index]}\\n')\n",
    "\n",
    "    site = site_name_list[index]\n",
    "    filename = files_list[index]\n",
    "    df_classes = df_sites.loc[df_sites['sites_ids'] == site]\n",
    "    number_clusters = df_classes['classes'].values.tolist()[0]\n",
    "    fetch_70 = df_classes['FETCH_70'].values.tolist()[0]\n",
    "\n",
    "    boundaries, latitude, longitude, information = get_coordinates_area(df_sites, site)\n",
    "    m, gdf = map_coordinates_area(df_sites, boundaries, site)\n",
    "    Map, aoi = get_gee_area_from_gpp_multipolygon_single_polygon(boundaries, gdf, 6)\n",
    "\n",
    "    date_range = pd.date_range(start=date_range_values[0], end=date_range_values[1], freq='D')\n",
    "    dates_list = date_range.strftime('%Y-%m-%d').tolist()\n",
    "    year_list = get_unique_years(dates_list)\n",
    "\n",
    "    env_testing, gpp_testing = get_testing_data(directory_data, filename, expected_columns, 'GPP_DT_VUT_REF')\n",
    "    gpp_predicted = predict_gpp_df(env_testing, model_file)\n",
    "    gpp_predicted['GPP_testing'] = gpp_testing \n",
    "\n",
    "    for year in year_list:\n",
    "        print(f'Calculating uncerstainty product for {site} in {year}\\n')\n",
    "\n",
    "        df, mse, test_r2, mae, rmse = get_performance(gpp_predicted, year)\n",
    "\n",
    "        ic, point = get_collection_without_clouds('COPERNICUS/S2_SR_HARMONIZED',[year],aoi,longitude,latitude,max_cloud_coverage,local_cloud_coverage)\n",
    "        bands = ic.first().bandNames().getInfo() \n",
    "        inputML, cluster_ecosystem_image, cluster_ecosystem_geometry = get_ecosystem_geometry(training_dataset,number_clusters,training_scale,scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent)\n",
    "        ecosystem_map = get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year, point, fetch_70)\n",
    "        # Map = map_image(cluster_ecosystem_image.first(), aoi, \"cluster\", \"Cluster\")\n",
    "        plot_save_et(cluster_ecosystem_image,aoi, site, year, directory_maps, mse, test_r2, mae, rmse)\n",
    "\n",
    "        et_sample = cluster_ecosystem_image.getRegion(aoi, 10).getInfo()\n",
    "        df_et =  get_et_df(et_sample, year)\n",
    "        ds_et = df_et.to_xarray()\n",
    "\n",
    "        for index in range(len(dates_list)-1):\n",
    "            period = [dates_list[index], dates_list[index+1]]\n",
    "            print(f\"Period: {dates_list[index]}, {dates_list[index+1]}\")\n",
    "            \n",
    "            try:\n",
    "                try:\n",
    "                    number_img = 0\n",
    "                    s2_array, s2 = get_s2_array(period, aoi, sentinel, number_img, MGRS_TILE=MGRS_TILE, cloud_percentage=100, resolution=10)\n",
    "                    s2_df = get_s2_df(s2_array)\n",
    "                    s2_df = s2_df.dropna()\n",
    "                    if not s2_df.empty:\n",
    "                        env_df = get_environmental_data(directory_data, filename, sentinel, bands, general)\n",
    "                        df_merged = merge_s2_env_data(s2_df, env_df, expected_columns)\n",
    "                        ds_gpp, df_gpp = predict_gpp(df_merged, model_file)\n",
    "                        #plot_save_gpp(ds_gpp, site, period, directory_maps)\n",
    "\n",
    "                        s2_array, s2 = get_s2_array_nomasked(period,aoi,sentinel_full, number_img, MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "                        s2_df = get_s2_df(s2_array)\n",
    "                        df_final = s2_df.merge(df_gpp['GPP'], left_index=True, right_index=True, how='left')\n",
    "                        df_final = df_final.reset_index(level=['time','latitude','longitude'])\n",
    "\n",
    "                        df_final = df_final.merge(df_et['cluster'], on=['latitude', 'longitude'], how='left')\n",
    "                        df_final = df_final.set_index(['time','latitude','longitude'])\n",
    "                        df_final = df_final.rename(columns={'cluster': 'uncertainty'})\n",
    "                        df_final.loc[df_final['uncertainty'] == 0, 'GPP'] = np.nan\n",
    "                        count_non_nan_gpp = df_final['GPP'].notna().sum()\n",
    "                        count_ones = df_final['uncertainty'].value_counts().get(1, 0)\n",
    "                        ratio_data = count_non_nan_gpp / count_ones\n",
    "\n",
    "                        if ratio_data > 0.5:\n",
    "                            ds_gpp = df_final.to_xarray()\n",
    "                            plot_save_gpp_all_data(ds_gpp, site, period, directory_maps)\n",
    "                        else:\n",
    "                            print('The GPP data of interest is below 50 percent of the validated area')\n",
    "\n",
    "                    else:\n",
    "                        print('This dataset is empty')\n",
    "                        # s2_array, s2 = get_s2_array_nomasked(period,aoi,sentinel_full, number_img, MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "                        # s2_df = get_s2_df(s2_array)\n",
    "                        # s2_df['GPP'] = np.nan\n",
    "                        # ds_gpp = s2_df.to_xarray()\n",
    "                        # plot_save_gpp_all_data(ds_gpp, site, period, directory_maps)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Handle any other exceptions\n",
    "                    print(f\"An unexpected error occurred: {e}\")\n",
    "                    print('Trying with second error in collection')\n",
    "                    number_img = 1\n",
    "                    s2_array, s2 = get_s2_array(period,aoi,sentinel, number_img, MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "                    s2_df = get_s2_df(s2_array)\n",
    "                    s2_df = s2_df.dropna()\n",
    "                    if not s2_df.empty:\n",
    "                        env_df = get_environmental_data(directory_data, filename, sentinel, bands, general)\n",
    "                        df_merged = merge_s2_env_data(s2_df, env_df, expected_columns)\n",
    "                        ds_gpp, df_gpp = predict_gpp(df_merged, model_file)\n",
    "                        #plot_save_gpp(ds_gpp, site, period, directory_maps)\n",
    "\n",
    "                        s2_array, s2 = get_s2_array_nomasked(period,aoi,sentinel_full, number_img, MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "                        s2_df = get_s2_df(s2_array)\n",
    "                        df_final = s2_df.merge(df_gpp['GPP'], left_index=True, right_index=True, how='left')\n",
    "                        df_final = df_final.reset_index(level=['time','latitude','longitude'])\n",
    "\n",
    "                        df_final = df_final.merge(df_et['cluster'], on=['latitude', 'longitude'], how='left')\n",
    "                        df_final = df_final.set_index(['time','latitude','longitude'])\n",
    "                        df_final = df_final.rename(columns={'cluster': 'uncertainty'})\n",
    "                        df_final.loc[df_final['uncertainty'] == 0, 'GPP'] = np.nan\n",
    "                        count_non_nan_gpp = df_final['GPP'].notna().sum()\n",
    "                        count_ones = df_final['uncertainty'].value_counts().get(1, 0)\n",
    "                        ratio_data = count_non_nan_gpp / count_ones\n",
    "\n",
    "                        if ratio_data > 0.5:\n",
    "                            ds_gpp = df_final.to_xarray()\n",
    "                            plot_save_gpp_all_data(ds_gpp, site, period, directory_maps)\n",
    "                        else:\n",
    "                            print('The GPP data of interest is below 50 percent of the validated area')\n",
    "\n",
    "                    else:\n",
    "                        print('This dataset is empty')\n",
    "                        # s2_array, s2 = get_s2_array_nomasked(period,aoi,sentinel_full, number_img, MGRS_TILE=MGRS_TILE,cloud_percentage=100,resolution=10)\n",
    "                        # s2_df = get_s2_df(s2_array)\n",
    "                        # s2_df['GPP'] = np.nan\n",
    "                        # ds_gpp = s2_df.to_xarray()\n",
    "                        # plot_save_gpp_all_data(ds_gpp, site, period, directory_maps)\n",
    "            except ee.EEException as ee_error:\n",
    "                print(f\"Earth Engine Exception: {ee_error}\\n\")\n",
    "\n",
    "        # for year in year_list:\n",
    "        #     print(f'Calculating uncerstainty product for {site} in {year}\\n')\n",
    "\n",
    "        #     df, mse, test_r2, mae, rmse = get_performance(gpp_predicted, year)\n",
    "\n",
    "        #     ic, point = get_collection_without_clouds('COPERNICUS/S2_SR_HARMONIZED',[year],aoi,longitude,latitude,max_cloud_coverage,local_cloud_coverage)\n",
    "        #     bands = ic.first().bandNames().getInfo() \n",
    "        #     inputML, cluster_ecosystem_image, cluster_ecosystem_geometry = get_ecosystem_geometry(training_dataset,number_clusters,training_scale,scale_getRegion, vector_scale, point, ic, bands, ecosystem_extent)\n",
    "        #     ecosystem_map = get_ecosystem_map(latitude,longitude,cluster_ecosystem_geometry, inputML, directory_maps, site, year, point, fetch_70)\n",
    "        #     # Map = map_image(cluster_ecosystem_image.first(), aoi, \"cluster\", \"Cluster\")\n",
    "        #     plot_save_et(cluster_ecosystem_image,aoi, site, year, directory_maps, mse, test_r2, mae, rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deltares_GPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
